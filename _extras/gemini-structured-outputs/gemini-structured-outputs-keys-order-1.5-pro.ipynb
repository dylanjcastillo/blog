{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "18dc8ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4274c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "33194d54-582b-4b81-a195-8f1269a438a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T20:37:59.673511Z",
     "iopub.status.busy": "2024-11-17T20:37:59.673328Z",
     "iopub.status.idle": "2024-11-17T20:38:07.222035Z",
     "shell.execute_reply": "2024-11-17T20:38:07.221730Z",
     "shell.execute_reply.started": "2024-11-17T20:37:59.673491Z"
    }
   },
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from typing import Literal\n",
    "\n",
    "import google.generativeai as genai\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MODEL_NAME = \"gemini-1.5-pro-002\"\n",
    "NUMBER_OF_TESTS = 10\n",
    "MAX_CONCURRENCY = 20\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6752e44d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ab57a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = [\n",
    "    \"apples\",\n",
    "    \"oranges\",\n",
    "    \"bananas\",\n",
    "    \"coconuts\",\n",
    "    \"pears\",\n",
    "    \"peaches\",\n",
    "    \"grapes\",\n",
    "    \"watermelons\",\n",
    "    \"strawberries\",\n",
    "    \"blueberries\",\n",
    "    \"raspberries\",\n",
    "    \"blackberries\",\n",
    "    \"cherries\",\n",
    "    \"plums\",\n",
    "    \"apricots\",\n",
    "    \"kiwis\",\n",
    "    \"mangos\",\n",
    "    \"papayas\",\n",
    "    \"pineapples\",\n",
    "    \"pomegranates\",\n",
    "    \"tangerines\",\n",
    "]\n",
    "\n",
    "assert len(fruits) == len(set(fruits))\n",
    "\n",
    "\n",
    "def generate_test(\n",
    "    json_schema_representation: Literal[\"exclude\", \"class\", \"json_schema\"],\n",
    "):\n",
    "    random.seed(42)\n",
    "    fruits_sample = random.sample(fruits, 5)\n",
    "    numbers_sample = random.sample(range(1, 100), 5)\n",
    "    properties = {\n",
    "        fruits_sample[0]: genai.protos.Schema(type=genai.protos.Type.INTEGER),\n",
    "        fruits_sample[1]: genai.protos.Schema(type=genai.protos.Type.INTEGER),\n",
    "        fruits_sample[2]: genai.protos.Schema(type=genai.protos.Type.INTEGER),\n",
    "        fruits_sample[3]: genai.protos.Schema(type=genai.protos.Type.INTEGER),\n",
    "        fruits_sample[4]: genai.protos.Schema(type=genai.protos.Type.INTEGER),\n",
    "    }\n",
    "    system_prompt = \"You're a helpful assistant. Please produce the answer according to the JSON schema.\"\n",
    "    if json_schema_representation == \"exclude\":\n",
    "        system_prompt += f\"{json_schema_representation}\"\n",
    "    if json_schema_representation == \"class\":\n",
    "        class_str = f\"\\n\\nclass Response(BaseModel):\\n    {fruits_sample[0]}: int\\n    {fruits_sample[1]}: int\\n    {fruits_sample[2]}: int\\n    {fruits_sample[3]}: int\\n    {fruits_sample[4]}: int\"\n",
    "        system_prompt += f\"{class_str}\"\n",
    "    if json_schema_representation == \"json_schema\":\n",
    "        json_schema = {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                fruits_sample[0]: {\"type\": \"integer\"},\n",
    "                fruits_sample[1]: {\"type\": \"integer\"},\n",
    "                fruits_sample[2]: {\"type\": \"integer\"},\n",
    "                fruits_sample[3]: {\"type\": \"integer\"},\n",
    "                fruits_sample[4]: {\"type\": \"integer\"},\n",
    "            },\n",
    "            \"required\": list(properties.keys()),\n",
    "        }\n",
    "        system_prompt += f\"\\n\\n{json.dumps(json_schema)}\"\n",
    "    user_question = f\"Given that I have {numbers_sample[0]} {fruits_sample[0]}, {numbers_sample[1]} {fruits_sample[1]}, {numbers_sample[2]} {fruits_sample[2]}, {numbers_sample[3]} {fruits_sample[3]}, {numbers_sample[4]} {fruits_sample[4]}, represent these counts according to the schema.\"\n",
    "    return system_prompt, properties, user_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c1db455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_content_structured_output(test: tuple):\n",
    "    model_structured_output = genai.GenerativeModel(\n",
    "        model_name=MODEL_NAME,\n",
    "        generation_config=genai.GenerationConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "            response_schema=genai.protos.Schema(\n",
    "                type=genai.protos.Type.OBJECT,\n",
    "                properties=test[1],\n",
    "                required=list(test[1].keys()),\n",
    "            ),\n",
    "        ),\n",
    "        system_instruction=test[0],\n",
    "    )\n",
    "    response = await model_structured_output.generate_content_async(test[2])\n",
    "    return response.text\n",
    "\n",
    "\n",
    "async def generate_content_function_call(test: tuple):\n",
    "    model_function_call = genai.GenerativeModel(\n",
    "        model_name=MODEL_NAME,\n",
    "        generation_config=genai.GenerationConfig(\n",
    "            response_mime_type=\"text/plain\",\n",
    "        ),\n",
    "        tools=[\n",
    "            genai.protos.Tool(\n",
    "                function_declarations=[\n",
    "                    genai.protos.FunctionDeclaration(\n",
    "                        name=\"Response\",\n",
    "                        description=\"Correctly extracted `Response` with all the required parameters\",\n",
    "                        parameters=genai.protos.Schema(\n",
    "                            type=genai.protos.Type.OBJECT,\n",
    "                            properties=test[1],\n",
    "                            required=list(test[1].keys()),\n",
    "                        ),\n",
    "                    )\n",
    "                ],\n",
    "            )\n",
    "        ],\n",
    "        tool_config={\"function_calling_config\": \"ANY\"},\n",
    "        system_instruction=test[0],\n",
    "    )\n",
    "    response = await model_function_call.generate_content_async(test[2])\n",
    "    for part in response.parts:\n",
    "        if fn := part.function_call:\n",
    "            return json.dumps(dict(fn.args))\n",
    "    return None\n",
    "\n",
    "\n",
    "async def generate_content_function_call_with_mime_type(test: tuple):\n",
    "    model_function_call = genai.GenerativeModel(\n",
    "        model_name=MODEL_NAME,\n",
    "        generation_config=genai.GenerationConfig(\n",
    "            response_mime_type=\"application/json\",\n",
    "        ),\n",
    "        system_instruction=test[0],\n",
    "    )\n",
    "    response = await model_function_call.generate_content_async(test[2])\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def check_if_keys_sorted(output: str, properties: dict):\n",
    "    order_original_keys = [k for k in properties.keys()]\n",
    "    output_dict = json.loads(output)\n",
    "    order_output_keys = [k for k in output_dict.keys()]\n",
    "    return order_output_keys == order_original_keys\n",
    "\n",
    "\n",
    "def check_if_keys_sorted_alphabetically(output: str):\n",
    "    output_dict = json.loads(output)\n",
    "    output_original_order = [k for k in output_dict.keys()]\n",
    "    output_sorted_order = [k for k in sorted(output_dict.keys())]\n",
    "    return output_original_order == output_sorted_order\n",
    "\n",
    "\n",
    "async def run_single_test(test, call_fn, semaphore):\n",
    "    async with semaphore:\n",
    "        output = await call_fn(test)\n",
    "        keys_match = check_if_keys_sorted(output, test[1])\n",
    "        alpha_sorted = check_if_keys_sorted_alphabetically(output)\n",
    "        return output, keys_match, alpha_sorted\n",
    "\n",
    "\n",
    "async def run_tests(call_fn, tests):\n",
    "    semaphore = asyncio.BoundedSemaphore(MAX_CONCURRENCY)\n",
    "    tasks = []\n",
    "    for test in tests:\n",
    "        tasks.append(run_single_test(test, call_fn, semaphore))\n",
    "    return await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8c8cca",
   "metadata": {},
   "source": [
    "## Check if keys are in the correct order or alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a03213ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_class = [generate_test(\"class\") for _ in range(NUMBER_OF_TESTS)]\n",
    "tests_none = [generate_test(\"exclude\") for _ in range(NUMBER_OF_TESTS)]\n",
    "tests_json_schema = [generate_test(\"json_schema\") for _ in range(NUMBER_OF_TESTS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "25cee352",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_structured_output = asyncio.run(\n",
    "    run_tests(generate_content_structured_output, tests_none)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "38af5ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_function_call = asyncio.run(\n",
    "    run_tests(generate_content_function_call, tests_class)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "dd10e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_function_call_with_mime_type = asyncio.run(\n",
    "    run_tests(generate_content_function_call_with_mime_type, tests_class)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff72056",
   "metadata": {},
   "source": [
    "### Keys in correct order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cbdca15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in correct order (structured output): 0.00%\n",
      "Keys in correct order (function call): 0.00%\n",
      "Keys in correct order (function call with mime type): 100.00%\n"
     ]
    }
   ],
   "source": [
    "def pct_correct_keys(\n",
    "    test_results_structured_output,\n",
    "    test_results_function_call,\n",
    "    test_results_function_call_with_mime_type,\n",
    "):\n",
    "    correct_keys_count_structured_output = 0\n",
    "    correct_keys_count_function_call = 0\n",
    "    correct_keys_count_function_call_with_mime_type = 0\n",
    "\n",
    "    for test in zip(\n",
    "        test_results_structured_output,\n",
    "        test_results_function_call,\n",
    "        test_results_function_call_with_mime_type,\n",
    "    ):\n",
    "        if test[0][1]:\n",
    "            correct_keys_count_structured_output += 1\n",
    "        if test[1][1]:\n",
    "            correct_keys_count_function_call += 1\n",
    "        if test[2][1]:\n",
    "            correct_keys_count_function_call_with_mime_type += 1\n",
    "    print(\n",
    "        f\"Keys in correct order (structured output): {correct_keys_count_structured_output / NUMBER_OF_TESTS:.2%}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Keys in correct order (function call): {correct_keys_count_function_call / NUMBER_OF_TESTS:.2%}\"\n",
    "    )\n",
    "    if test_results_function_call_with_mime_type:\n",
    "        print(\n",
    "            f\"Keys in correct order (function call with mime type): {correct_keys_count_function_call_with_mime_type / NUMBER_OF_TESTS:.2%}\"\n",
    "        )\n",
    "\n",
    "\n",
    "pct_correct_keys(\n",
    "    test_results_structured_output,\n",
    "    test_results_function_call,\n",
    "    test_results_function_call_with_mime_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2265ab",
   "metadata": {},
   "source": [
    "### Keys in alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f4928dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in alphabetical order (structured output): 100.00%\n",
      "Keys in alphabetical order (function call): 0.00%\n",
      "Keys in alphabetical order (function call with mime type): 0.00%\n"
     ]
    }
   ],
   "source": [
    "def pct_alphabetical_keys(\n",
    "    test_results_structured_output,\n",
    "    test_results_function_call,\n",
    "    test_results_function_call_with_mime_type,\n",
    "):\n",
    "    correct_keys_count_alphabetical_structured_output = 0\n",
    "    correct_keys_count_alphabetical_function_call = 0\n",
    "    correct_keys_count_alphabetical_function_call_with_mime_type = 0\n",
    "\n",
    "    for test in zip(\n",
    "        test_results_structured_output,\n",
    "        test_results_function_call,\n",
    "        test_results_function_call_with_mime_type,\n",
    "    ):\n",
    "        if test[0][2]:\n",
    "            correct_keys_count_alphabetical_structured_output += 1\n",
    "        if test[1][2]:\n",
    "            correct_keys_count_alphabetical_function_call += 1\n",
    "        if test[2][2]:\n",
    "            correct_keys_count_alphabetical_function_call_with_mime_type += 1\n",
    "\n",
    "    print(\n",
    "        f\"Keys in alphabetical order (structured output): {correct_keys_count_alphabetical_structured_output / NUMBER_OF_TESTS:.2%}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Keys in alphabetical order (function call): {correct_keys_count_alphabetical_function_call / NUMBER_OF_TESTS:.2%}\"\n",
    "    )\n",
    "    if test_results_function_call_with_mime_type:\n",
    "        print(\n",
    "            f\"Keys in alphabetical order (function call with mime type): {correct_keys_count_alphabetical_function_call_with_mime_type / NUMBER_OF_TESTS:.2%}\"\n",
    "        )\n",
    "\n",
    "\n",
    "pct_alphabetical_keys(\n",
    "    test_results_structured_output,\n",
    "    test_results_function_call,\n",
    "    test_results_function_call_with_mime_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb086fb3",
   "metadata": {},
   "source": [
    "## Ask to keep the keys in the correct order in prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "81f0b097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_ask_to_keep_order(\n",
    "    json_schema_representation: Literal[\"exclude\", \"class\", \"json_schema\"],\n",
    "):\n",
    "    random.seed(42)\n",
    "    fruits_sample = random.sample(fruits, 5)\n",
    "    numbers_sample = random.sample(range(1, 100), 5)\n",
    "    properties = {\n",
    "        fruits_sample[0]: genai.protos.Schema(type=genai.protos.Type.INTEGER),\n",
    "        fruits_sample[1]: genai.protos.Schema(type=genai.protos.Type.INTEGER),\n",
    "        fruits_sample[2]: genai.protos.Schema(type=genai.protos.Type.INTEGER),\n",
    "        fruits_sample[3]: genai.protos.Schema(type=genai.protos.Type.INTEGER),\n",
    "        fruits_sample[4]: genai.protos.Schema(type=genai.protos.Type.INTEGER),\n",
    "    }\n",
    "    system_prompt = \"You're a helpful assistant. Please produce the answer according to the JSON schema. Make sure to keep the keys in the same order as the schema.\"\n",
    "    if json_schema_representation == \"exclude\":\n",
    "        system_prompt += f\"{json_schema_representation}\"\n",
    "    if json_schema_representation == \"class\":\n",
    "        class_str = f\"\\n\\nclass Response(BaseModel):\\n    {fruits_sample[0]}: int\\n    {fruits_sample[1]}: int\\n    {fruits_sample[2]}: int\\n    {fruits_sample[3]}: int\\n    {fruits_sample[4]}: int\"\n",
    "        system_prompt += f\"{class_str}\"\n",
    "    if json_schema_representation == \"json_schema\":\n",
    "        json_schema = {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                fruits_sample[0]: {\"type\": \"integer\"},\n",
    "                fruits_sample[1]: {\"type\": \"integer\"},\n",
    "                fruits_sample[2]: {\"type\": \"integer\"},\n",
    "                fruits_sample[3]: {\"type\": \"integer\"},\n",
    "                fruits_sample[4]: {\"type\": \"integer\"},\n",
    "            },\n",
    "            \"required\": list(properties.keys()),\n",
    "        }\n",
    "        system_prompt += f\"\\n\\n{json.dumps(json_schema)}\"\n",
    "    user_question = f\"Given that I have {numbers_sample[0]} {fruits_sample[0]}, {numbers_sample[1]} {fruits_sample[1]}, {numbers_sample[2]} {fruits_sample[2]}, {numbers_sample[3]} {fruits_sample[3]}, {numbers_sample[4]} {fruits_sample[4]}, represent these counts according to the schema.\"\n",
    "    return system_prompt, properties, user_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "eb9cde69",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_class = [generate_test_ask_to_keep_order(\"class\") for _ in range(NUMBER_OF_TESTS)]\n",
    "tests_none = [generate_test_ask_to_keep_order(\"exclude\") for _ in range(NUMBER_OF_TESTS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d5fcc7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_structured_output_ask_to_keep_order = asyncio.run(\n",
    "    run_tests(generate_content_structured_output, tests_none)\n",
    ")\n",
    "test_results_function_call_ask_to_keep_order = asyncio.run(\n",
    "    run_tests(generate_content_function_call, tests_class)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d43a2ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in correct order (structured output): 0.00%\n",
      "Keys in correct order (function call): 0.00%\n"
     ]
    }
   ],
   "source": [
    "pct_correct_keys(\n",
    "    test_results_structured_output_ask_to_keep_order,\n",
    "    test_results_function_call_ask_to_keep_order,\n",
    "    []\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1e8c838f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in alphabetical order (structured output): 0.00%\n",
      "Keys in alphabetical order (function call): 0.00%\n"
     ]
    }
   ],
   "source": [
    "pct_alphabetical_keys(\n",
    "    test_results_structured_output_ask_to_keep_order,\n",
    "    test_results_function_call_ask_to_keep_order,\n",
    "    [],\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
