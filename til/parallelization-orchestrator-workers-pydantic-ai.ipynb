{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b9ac1d5",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Parallelization and orchestrator-worker workflows with Pydantic AI\"\n",
    "date: 2025-07-09\n",
    "description-meta: \"Using Pydantic AI to build the parallelization and orchestrator-worker agentic workflows\"\n",
    "categories:\n",
    "  - til\n",
    "  - llm\n",
    "  - pydantic-ai\n",
    "  - workflows \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5c3bca",
   "metadata": {},
   "source": [
    "I've been re-implementing typical patterns for building [agentic](https://dylancastillo.co/til/react-agent-pydantic-ai.html) [systems](https://dylancastillo.co/posts/agentic-workflows-langgraph.html) with Pydantic AI. In this post, I'll explore how to build a [parallelization](https://www.anthropic.com/engineering/building-effective-agents#workflow-parallelization) and [orchestrator-worker](https://www.anthropic.com/engineering/building-effective-agents#workflow-orchestrator-worker) workflow.\n",
    "\n",
    "In previous TILs, I've explored:\n",
    "\n",
    "- [Prompt chaining](https://dylancastillo.co/til/prompt-chaining-pydantic-ai.html)\n",
    "- [Routing](https://dylancastillo.co/til/routing-pydantic-ai.html)\n",
    "- [Evaluator-optimizer](https://dylancastillo.co/til/evaluator-optimizer-pydantic-ai.html)\n",
    "- [ReAct agent](https://dylancastillo.co/til/react-agent-pydantic-ai.html)\n",
    "\n",
    "You can download this notebook [here](https://github.com/dcastillo/blog/blob/main/til/parallelization-orchestrator-workers-pydantic-ai.ipynb).\n",
    "\n",
    "## What is parallelization?\n",
    "\n",
    "This workflow is designed for tasks that can be easily divided into independent subtasks. The key trade-off is managing complexity and coordination overhead in exchange for significant speed improvements or diverse perspectives.\n",
    "\n",
    "It looks like this:\n",
    "\n",
    "```{mermaid}\n",
    "flowchart LR\n",
    "    In([In]) --> LLM1[\"LLM Call 1\"]\n",
    "    In --> LLM2[\"LLM Call 2\"]\n",
    "    In --> LLM3[\"LLM Call 3\"]\n",
    "    LLM1 --> Aggregator[\"Aggregator\"] \n",
    "    LLM2 --> Aggregator[\"Aggregator\"] \n",
    "    LLM3 --> Aggregator[\"Aggregator\"] \n",
    "    Aggregator --> Out([Out])\n",
    "```\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "- Evaluate multiple independent aspects of a text (safety, quality, relevance)\n",
    "- Process user query and apply guardrails in parallel\n",
    "- Generate multiple response candidates given a query for comparison\n",
    "\n",
    "## What is orchestrator-worker?\n",
    "\n",
    "This workflow works well for tasks where you don't know the required subtasks beforehand. The subtasks are determined by the orchestrator.\n",
    "\n",
    "Here's a diagram:\n",
    "\n",
    "```{mermaid}\n",
    "flowchart LR\n",
    "    In([In]) --> Orch[Orchestrator]\n",
    "\n",
    "    Orch -.-> LLM1[\"LLM Call 1\"]\n",
    "    Orch -.-> LLM2[\"LLM Call 2\"]\n",
    "    Orch -.-> LLM3[\"LLM Call 3\"]\n",
    "\n",
    "    LLM1 -.-> Synth[Synthesizer]\n",
    "    LLM2 -.-> Synth\n",
    "    LLM3 -.-> Synth\n",
    "\n",
    "    Synth --> Out([Out])\n",
    "\n",
    "```\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "- Coding tools making changes to multiple files at once\n",
    "- Searching multiple sources and synthesize the results\n",
    "\n",
    "The difference between parallelization and orchestrator-worker is that in parallelization, the subtasks are known beforehand, while in orchestrator-worker, the subtasks are determined by the orchestrator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce750c5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a10e8e",
   "metadata": {},
   "source": [
    "Pydantic AI uses `asyncio` under the hood, so you'll need to enable `nest_asyncio` to run this notebook: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a607486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5193cf3",
   "metadata": {},
   "source": [
    "Then, you need to import the required libraries. I'm using **[Logfire](https://logfire.pydantic.dev/)** to monitor the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4081c493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from pprint import pprint\n",
    "from typing import Literal, Optional\n",
    "\n",
    "import logfire\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent, RunContext\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e5695",
   "metadata": {},
   "source": [
    "**PydanticAI** is compatible with OpenTelemetry (OTel). So it's pretty easy to use it with Logfire or with any other OTel-compatible observability tool (e.g., [Langfuse](https://langfuse.com/)).\n",
    "\n",
    "To enable tracking, create a project in Logfire, generate a `Write token` and add it to the `.env` file. Then, you just need to run: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "014a1f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "logfire.configure(\n",
    "    token=os.getenv(\"LOGFIRE_TOKEN\"),\n",
    ")\n",
    "logfire.instrument_pydantic_ai()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a02dc0",
   "metadata": {},
   "source": [
    "The first time you run this, it will ask you to create a project in Logfire. From it, it will generate a `logfire_credentials.json` file in your working directory. In following runs, it will automatically use the credentials from the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c8cc51",
   "metadata": {},
   "source": [
    "## Parallelization example \n",
    "\n",
    "In this example, I'll show you how to build a workflow that runs the same evaluator in parallel and then aggregates the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a49b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation(BaseModel):\n",
    "    explanation: str\n",
    "    is_appropiate: bool\n",
    "\n",
    "\n",
    "class AggregatedResults(BaseModel):\n",
    "    summary: str\n",
    "    is_appropiate: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a5d3a",
   "metadata": {},
   "source": [
    "Then you can create the agents and encapsulate the logic in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3db5d8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:28:36.289 Run workflow\n",
      "15:28:36.290   agent run\n",
      "15:28:36.290     chat gpt-4.1-mini\n",
      "15:28:36.291   agent run\n",
      "15:28:36.291     chat gpt-4.1-mini\n",
      "15:28:36.292   agent run\n",
      "15:28:36.292     chat gpt-4.1-mini\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Logfire</span> project URL: <a href=\"https://logfire-us.pydantic.dev/dylanjcastillo/blog\" target=\"_blank\"><span style=\"color: #008080; text-decoration-color: #008080; text-decoration: underline\">https://logfire-us.pydantic.dev/dylanjcastillo/blog</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mLogfire\u001b[0m project URL: \u001b]8;id=159968;https://logfire-us.pydantic.dev/dylanjcastillo/blog\u001b\\\u001b[4;36mhttps://logfire-us.pydantic.dev/dylanjcastillo/blog\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:28:39.380   aggregator run\n",
      "15:28:39.380     chat gpt-4.1-mini\n"
     ]
    }
   ],
   "source": [
    "evaluator = Agent(\n",
    "    \"openai:gpt-4.1-mini\",\n",
    "    output_type=Evaluation,\n",
    "    system_prompt=(\n",
    "        \"You are an expert evaluator. Provided with a text, you will evaluate if it's appropriate for a general audience.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "aggregator = Agent(\n",
    "    \"openai:gpt-4.1-mini\",\n",
    "    output_type=AggregatedResults,\n",
    "    system_prompt=(\n",
    "        \"You are an expert evaluator. Provided with a list of evaluations, you will summarize them and provide a final evaluation.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "@logfire.instrument(\"Run workflow\")\n",
    "async def run_workflow(topic: str) -> str:\n",
    "    tasks = [evaluator.run(f\"Evaluate the following text: {topic}\") for _ in range(3)]\n",
    "    evaluations = await asyncio.gather(*tasks)\n",
    "    aggregated_results = await aggregator.run(f\"Summarize the following evaluations:\\n\\n{[(eval.output.explanation, eval.output.is_appropiate) for eval in evaluations]}\")\n",
    "    return aggregated_results.output\n",
    "\n",
    "output = await run_workflow(\"Athletes should consume enhancing drugs to improve their performance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7a4c12",
   "metadata": {},
   "source": [
    "Finally, you can run the workflow. You should get an output like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48f317fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is_appropiate': False,\n",
      " 'summary': 'All evaluations agree that the text promotes the consumption of '\n",
      "            'performance-enhancing drugs by athletes, which is a sensitive and '\n",
      "            'controversial topic. The main concerns highlighted are health '\n",
      "            'risks, ethical issues, fairness in sports, and legality. The '\n",
      "            'evaluations consistently indicate that encouraging or normalizing '\n",
      "            'the use of such drugs is inappropriate for a general audience as '\n",
      "            'it may promote illegal, harmful, or unsafe behavior. There is '\n",
      "            'consensus that the subject should be handled with caution.'}\n"
     ]
    }
   ],
   "source": [
    "pprint(output.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9c94cd",
   "metadata": {},
   "source": [
    "## Orchestrator-workers example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e5fec",
   "metadata": {},
   "source": [
    "In this example, I'll show you how to build a workflow that given a topic generates a table of contents, then writes each section of the article by making an individual request to an LLM.\n",
    "\n",
    "First, you must define the structures we'll use in the outputs of the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65b82dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Section(BaseModel):\n",
    "    name: str = Field(description=\"The name of the section\")\n",
    "    description: str = Field(description=\"The description of the section\")\n",
    "\n",
    "\n",
    "class CompletedSection(BaseModel):\n",
    "    name: str = Field(description=\"The name of the section\")\n",
    "    content: str = Field(description=\"The content of the section\")\n",
    "\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections: list[Section] = Field(description=\"The sections of the article\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9d0113",
   "metadata": {},
   "source": [
    "Then, we'll define the agents we'll use in the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "797497f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestrator = Agent(\n",
    "    \"openai:gpt-4.1-mini\",\n",
    "    output_type=Sections,\n",
    "    system_prompt=(\n",
    "        \"You are an expert writer specialized in SEO. Provided with a topic, you will generate the sections for a short article.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "worker = Agent(\n",
    "    \"openai:gpt-4.1-mini\",\n",
    "    output_type=CompletedSection,\n",
    "    system_prompt=(\n",
    "        \"You are an expert writer specialized in SEO. Provided with a topic and a section, you will generate the content of the section.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "def synthesizer(sections: list[CompletedSection]) -> str:\n",
    "    completed_sections_str = \"\\n\\n\".join(\n",
    "        [section.content for section in sections]\n",
    "    )\n",
    "    return completed_sections_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dac1469",
   "metadata": {},
   "source": [
    "Then, you can define a function that orchestrates the workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71597e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:32:13.934 Run workflow\n",
      "15:32:13.936   orchestrator run\n",
      "15:32:13.937     chat gpt-4.1-mini\n",
      "15:32:18.567   agent run\n",
      "15:32:18.568     chat gpt-4.1-mini\n",
      "15:32:18.569   agent run\n",
      "15:32:18.569     chat gpt-4.1-mini\n",
      "15:32:18.570   agent run\n",
      "15:32:18.571     chat gpt-4.1-mini\n",
      "15:32:18.572   agent run\n",
      "15:32:18.572     chat gpt-4.1-mini\n",
      "15:32:18.573   agent run\n",
      "15:32:18.573     chat gpt-4.1-mini\n"
     ]
    }
   ],
   "source": [
    "@logfire.instrument(\"Run workflow\")\n",
    "async def run_workflow(topic: str) -> str:\n",
    "    orchestrator_output = await orchestrator.run(f\"Generate the sections for a short article about {topic}\")\n",
    "    tasks = [worker.run(f\"Write the section {section.name} about {topic} with the following description: {section.description}\") for section in orchestrator_output.output.sections]\n",
    "    completed_sections = await asyncio.gather(*tasks)\n",
    "    full_article = synthesizer([c.output for c in completed_sections])\n",
    "    return full_article\n",
    "\n",
    "output = await run_workflow(\"Artificial Intelligence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff295f2",
   "metadata": {},
   "source": [
    "That's all!\n",
    "\n",
    "If you want to see the full code, you can download the notebook [here](https://github.com/dcastillo/blog/blob/main/til/parallelization-orchestrator-workers-pydantic-ai.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
