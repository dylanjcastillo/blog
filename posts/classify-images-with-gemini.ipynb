{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Classify images with Gemini Flash 1.5\"\n",
    "date: \"10/08/2024\"\n",
    "date-modified: last-modified\n",
    "description-meta: \"Learn how to use In-Context Learning (ICL) to classify images using Gemini Flash 1.5\"\n",
    "toc: true\n",
    "toc-depth: 3\n",
    "lightbox: true\n",
    "fig-cap-location: margin\n",
    "categories:\n",
    "  - mllms\n",
    "  - in-context-learning\n",
    "  - gemini\n",
    "author:\n",
    "  - name: Dylan Castillo\n",
    "    url: https://dylancastillo.co\n",
    "    affiliation: Iwana Labs\n",
    "    affiliation-url: https://iwanalabs.com\n",
    "    citation: true\n",
    "    comments:\n",
    "    utterances:\n",
    "    repo: dylanjcastillo/blog_comments\n",
    "    theme: dark-blue\n",
    "    issue-term: pathname\n",
    "draft: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One overlooked aspect of Multimodal Large Language Models (MLLMs) is the ability to use In-Context Learning (ICL) to classify images. This is a technique that allows the model to learn from a small number of ground truth images provided at inference time and make predictions on previously unseen images.\n",
    "\n",
    "This approach has been demonstrated to work quite well for image classification tasks in the literature (see [here](https://arxiv.org/abs/2405.09798) and [here](https://arxiv.org/abs/2403.07407)), and I've also had success with it in the past. While you're unlikely to achieve state-of-the-art results with it, it can often give you pretty good results with very little effort and data.\n",
    "\n",
    "I recently worked on a project for a client that made use of this approach, so I thought it'd be fun to write a short tutorial about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To follow this tutorial you'll need to:\n",
    "\n",
    "- Generate a key in [Google AI Studio](https://aistudio.google.com/app/apikey)\n",
    "- Download [EuroSAT](https://github.com/phelber/EuroSAT)\n",
    "- Create a virtual environment and install the requirements:\n",
    "\n",
    "```bash\n",
    "python -m venv venv\n",
    "source venv/bin/activate\n",
    "pip install pandas numpy scikit-learn nest-asyncio google-generativeai pillow\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Gemini Flash 1.5?\n",
    "\n",
    "You can use any MLLM for this task, but I like Gemini Flash 1.5 because:\n",
    "\n",
    "1. It's cheaper than [Gemini Pro 1.5](https://ai.google.dev/pricing), [GPT-4o](https://platform.openai.com/pricing), and [Sonnet 3.5](https://docs.anthropic.com/en/docs/build-with-claude/vision#calculate-image-costs). For an image of 512x512 pixels, Gemini Flash 1.5 is 66x cheaper than Gemini Pro 1.5, 32x cheaper than GPT-4o, and 52x cheaper than Sonnet 3.5[^longnote].\n",
    "2. It lets you use up to 3,000 images per request. By trial and error, I found that GPT-4o seems to have a hard limit at 250 images per request and Sonnet 3.5's documentation mentions a limit of 20 images per request.\n",
    "3. It works well enough for this task. If you really want to squeeze the last bit of performance out of your model, you can use a bigger model, but for the purposes of this tutorial, Gemini Flash 1.5 will do just fine.\n",
    "\n",
    "Regardless of the model you choose, this tutorial will be a good starting point for you to classify images using ICL.\n",
    "\n",
    "[^longnote]: Estimated costs as of August 10, 2024:\n",
    "\n",
    "    | Model | Cost per 512x512 image |\n",
    "    |-------|------------------------|\n",
    "    | Gemini Flash 1.5 | $0.00002 |\n",
    "    | Gemini Pro 1.5 | $0.000064 |\n",
    "    | GPT-4o | $0.000638 |\n",
    "    | Sonnet 3.5 | $0.001047 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "#| echo: false\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nest_asyncio` makes it possible to run async code in Jupyter notebooks. You can enable it in your notebook by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import base64\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import google.generativeai as genai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from PIL import Image as PILImage\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(data_dir, n_train=5, n_test=10):\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    \n",
    "    for class_id, class_name in enumerate(sorted(os.listdir(data_dir))):\n",
    "        class_dir = Path(data_dir) / class_name\n",
    "        if not class_dir.is_dir():\n",
    "            continue\n",
    "        \n",
    "        image_files = sorted(class_dir.glob('*.jpg'))\n",
    "        \n",
    "        # Train dataset: first 10 images\n",
    "        for img_path in image_files[:n_train]:\n",
    "            class_letter = chr(64 + class_id)  # A, B, C, ...\n",
    "            generated_class_name = f\"class_{class_letter}\"\n",
    "            train_data.append({\n",
    "                'image_path': str(img_path),\n",
    "                'class_id': generated_class_name,\n",
    "                'class_name': class_name\n",
    "            })\n",
    "        \n",
    "        # Test dataset: next 20 images\n",
    "        for img_path in image_files[n_train:n_train+n_test]:\n",
    "            class_letter = chr(64 + class_id)  # A, B, C, ...\n",
    "            generated_class_name = f\"class_{class_letter}\"\n",
    "            test_data.append({\n",
    "                'image_path': str(img_path),\n",
    "                'class_id': generated_class_name,\n",
    "                'class_name': class_name\n",
    "            })\n",
    "    \n",
    "    df_train = pd.DataFrame(train_data)\n",
    "    df_test = pd.DataFrame(test_data).sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read dataframes and filter out non matching items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/EuroSAT_RGB/\"\n",
    "\n",
    "df_train, df_test = create_datasets(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_SYSTEM_PROMPT = \"\"\"You are an satellite imagery classification expert. Your task is to match input images from a satellite and assign a label based on the most similar context image. \n",
    "\n",
    "Provided with a list of context images and a list of input images, compare each input image to all context images for each class and determine the best matching context image for each input image and assign a label and confidence score. \n",
    "\n",
    "Provide your output as a JSON object in the following format:\n",
    "\n",
    "{\n",
    "    \"number_of_labeled_images\": <integer>,\n",
    "    \"output\": [\n",
    "        {\n",
    "            \"image_id\": <image id, integer, starts at 0>,\n",
    "            \"confidence\": <number between 0 and 10, the higher the more confident, integer>,\n",
    "            \"correct_label\": <label of the most similar context image, string>\n",
    "        }, \n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "\n",
    "## Instructions \n",
    "\n",
    "1. Carefully examine each input image.\n",
    "2. Compare it to all context images for each class.\n",
    "3. Determine the most similar context image for each input image and assign that label to the input image.\n",
    "4. Assign a confidence score between 0 and 10, where 10 indicates the highest confidence in the match.\n",
    "\n",
    "## Guidelines\n",
    "\n",
    "- ALWAYS produce valid JSON.\n",
    "- Generate ONLY a single prediction per input image. DO NOT produce duplicated predictions for any input image.\n",
    "- Make a prediction for ALL input images. If there's no matching label, classify it with the most similar label.\n",
    "- Each input image must be assigned a SINGLE label based on the context images. \n",
    "- You MUST only predict the context image labels provided.\n",
    "- The `number_of_labeled_images` MUST be the same as the number of input images.\n",
    "\n",
    "## Example\n",
    "\n",
    "This is an example of a valid output:\n",
    "```\n",
    "{\n",
    "  \"number_of_labeled_images\": 5,\n",
    "  \"output\": [\n",
    "      {\n",
    "        \"image_id\": 0,\n",
    "        \"confidence\": 10,\n",
    "        \"correct_label\": \"class_B\"\n",
    "      },\n",
    "      {\n",
    "        \"image_id\": 1,\n",
    "        \"confidence\": 9,\n",
    "        \"correct_label\": \"class_C\"\n",
    "      },\n",
    "      {\n",
    "        \"image_id\": 2,\n",
    "        \"confidence\": 4,\n",
    "        \"correct_label\": \"class_A\"\n",
    "      },\n",
    "      {\n",
    "        \"image_id\": 3,\n",
    "        \"confidence\": 2,\n",
    "        \"correct_label\": \"class_B\"\n",
    "      },\n",
    "      {\n",
    "        \"image_id\": 4,\n",
    "        \"confidence\": 10,\n",
    "        \"correct_label\": \"class_C\"\n",
    "      }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"application/json\",\n",
    "}\n",
    "classification_model = genai.GenerativeModel(\n",
    "    \"gemini-1.5-pro-exp-0827\", \n",
    "    system_instruction=CLASSIFIER_SYSTEM_PROMPT, \n",
    "    generation_config=generation_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "def image_to_base64(img_path):\n",
    "    img = PILImage.open(img_path)\n",
    "    buffered = BytesIO()\n",
    "    img.save(buffered, format=\"PNG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "def create_context_images_message(df):\n",
    "    messages = [\"Context images:\"]\n",
    "    grouped = df.groupby('class_name')\n",
    "    for class_name, group in grouped:\n",
    "        for _, row in group.iterrows():\n",
    "            base64_img = image_to_base64(row[\"image_path\"])\n",
    "            messages.append(base64_img)\n",
    "        messages.append(f\"correct_label: {class_name}\")\n",
    "    return messages\n",
    "\n",
    "def create_input_images_message(df):\n",
    "    messages = [\"Input images:\"]\n",
    "    for i, image_path in enumerate(df.image_path):\n",
    "        base64_img = image_to_base64(image_path)\n",
    "        image_message = [\n",
    "            base64_img,\n",
    "            f\"input_image_id: {i}\",\n",
    "        ]\n",
    "        messages.extend(image_message)\n",
    "    messages.append(f\"Please correctly classify all {df.shape[0]} images.\")\n",
    "    return messages\n",
    "    \n",
    "train_images_message = create_context_images_message(df_train)\n",
    "test_images_message = create_input_images_message(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images_by_class(df, class_id, max_images=5):\n",
    "    images_of_class = df[df['class_name'] == class_id]\n",
    "    html_content = '<div style=\"display: flex; flex-wrap: wrap;\">'\n",
    "    for i, (_, row) in enumerate(images_of_class.iterrows()):\n",
    "        if i >= max_images:\n",
    "            break\n",
    "        html_content += f'''\n",
    "        <div style=\"margin: 10px;\">\n",
    "            <img src=\"{row['image_path']}\" width=\"300\">\n",
    "            <p>Image path: {row['image_path']}</p>\n",
    "        </div>\n",
    "        '''\n",
    "    html_content += '</div>'\n",
    "\n",
    "    display(HTML(html_content))\n",
    "\n",
    "class_id = \"River\" \n",
    "display_images_by_class(df_test, class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_message[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = train_images_message + test_images_message[:3]\n",
    "response = await classification_model.generate_content_async(\n",
    "    contents=contents\n",
    ")\n",
    "response_json = json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [item['correct_label'] for item in response_json['output']]\n",
    "\n",
    "accuracy = accuracy_score(df_test.class_name, predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "f1 = f1_score(df_test.class_name, predictions, average='weighted')\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
