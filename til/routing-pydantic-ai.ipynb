{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b9ac1d5",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Routing workflow with Pydantic AI\"\n",
    "date: 2025-07-08\n",
    "description-meta: \"Using Pydantic AI to build the routing agentic workflow\"\n",
    "categories:\n",
    "  - til\n",
    "  - llm\n",
    "  - pydantic-ai\n",
    "  - workflows \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5c3bca",
   "metadata": {},
   "source": [
    "I'm trying to get more familiar with Pydantic AI, so I've been re-implementing typical patterns for building [agentic](https://dylancastillo.co/til/react-agent-pydantic-ai.html) [systems](https://dylancastillo.co/posts/agentic-workflows-langgraph.html). \n",
    "\n",
    "In this post, I'll build a [routing](https://www.anthropic.com/engineering/building-effective-agents#workflow-routing) workflow. I won't cover the basics of agentic workflows, so if you're not familiar with the concept, I recommend you to read [this post](https://dylancastillo.co/posts/agentic-workflows-langgraph.html) first.\n",
    "\n",
    "I've also written other TILs about Pydantic AI:\n",
    "\n",
    "- [Prompt chaining](https://dylancastillo.co/til/prompt-chaining-pydantic-ai.html)\n",
    "- [ReAct agent](https://dylancastillo.co/til/react-agent-pydantic-ai.html)\n",
    "- [Evaluator-optimizer](https://dylancastillo.co/til/evaluator-optimizer-pydantic-ai.html)\n",
    "- [Parallelization and Orchestrator-workers](https://dylancastillo.co/til/parallelization-orchestrator-workers-pydantic-ai.html)\n",
    "\n",
    "You can download this notebook [here](https://github.com/dcastillo/blog/blob/main/til/routing-pydantic-ai.ipynb).\n",
    "\n",
    "## What is router?\n",
    "\n",
    "Routing is a workflow pattern that takes the input, classifies it and then sends it to the right place for the best handling. This process can be managed by an LLM or a traditional classification model. It makes sense to use when a system needs to apply different logic to different types of queries.\n",
    "\n",
    "It looks like this:\n",
    "\n",
    "```{mermaid}\n",
    "flowchart LR \n",
    "    In([In]) --> Router[\"LLM Call Router\"]\n",
    "\n",
    "    Router -->|Route 1| LLM1[\"LLM Call 1\"]\n",
    "    Router -->|Route 2| LLM2[\"LLM Call 2\"]\n",
    "    Router -->|Route 3| LLM3[\"LLM Call 3\"]\n",
    "\n",
    "    LLM1 --> Out([Out])\n",
    "    LLM2 --> Out\n",
    "    LLM3 --> Out\n",
    "\n",
    "```\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "- Classify complexity of question and adjust model depending on it\n",
    "- Classify type of query and use specialized tools (e.g., indexes, prompts)\n",
    "\n",
    "Let's see how this looks like in code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce750c5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a10e8e",
   "metadata": {},
   "source": [
    "I will implement a workflow that will take a query from a user and will route it to the appropriate agent.\n",
    "\n",
    "There will be three agents in the workflow:\n",
    "\n",
    "- `Agent TOC`: Generate a table of contents for the article\n",
    "- `Agent Writer`: Generate the content of the article\n",
    "- `Agent Editor`: Update the content of the article if it's too long\n",
    "\n",
    "Because Pydantic AI uses `asyncio` under the hood, you need to enable `nest_asyncio` to use it in a notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a607486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5193cf3",
   "metadata": {},
   "source": [
    "Then, you need to import the required libraries. **[Logfire](https://logfire.pydantic.dev/)** is part of the Pydantic ecosystem, so I thought it'd be good to use it for observability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4081c493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "\n",
    "import logfire\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "from pydantic_ai import Agent, RunContext\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e5695",
   "metadata": {},
   "source": [
    "**PydanticAI** is compatible with OpenTelemetry (OTel). It's straightforward to use it with Logfire or with any other OTel-compatible observability tool (e.g., [Langfuse](https://langfuse.com/)).\n",
    "\n",
    "To enable tracking, create a project in Logfire, generate a `Write token` and add it to the `.env` file. Then, you just need to run: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "014a1f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "logfire.configure(\n",
    "    token=os.getenv(\"LOGFIRE_TOKEN\"),\n",
    ")\n",
    "logfire.instrument_pydantic_ai()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a02dc0",
   "metadata": {},
   "source": [
    "The first time you run this, it will ask you to create a project in Logfire. From it, it will generate a `logfire_credentials.json` file in your working directory. In following runs, it will automatically use the credentials from the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c8cc51",
   "metadata": {},
   "source": [
    "## Prompt chaining workflow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edbf064",
   "metadata": {},
   "source": [
    "As mentioned before, the workflow will be composed of three agents. So I created three `Agent` instances. Each one takes care of one of the tasks \n",
    "\n",
    "Here's the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4358c272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Logfire</span> project URL: <a href=\"https://logfire-us.pydantic.dev/dylanjcastillo/blog\" target=\"_blank\"><span style=\"color: #008080; text-decoration-color: #008080; text-decoration: underline\">https://logfire-us.pydantic.dev/dylanjcastillo/blog</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mLogfire\u001b[0m project URL: \u001b]8;id=850967;https://logfire-us.pydantic.dev/dylanjcastillo/blog\u001b\\\u001b[4;36mhttps://logfire-us.pydantic.dev/dylanjcastillo/blog\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class RouterOutput(BaseModel):\n",
    "    category: Literal[\"write_article\", \"generate_table_of_contents\", \"review_article\"]\n",
    "\n",
    "\n",
    "router_agent = Agent(\n",
    "    \"openai:gpt-4.1-mini\",\n",
    "    system_prompt=(\n",
    "        \"You are a helpful assistant. You will classify the message into one of the following categories: 'write_article', 'generate_table_of_contents', 'review_article'.\"\n",
    "    ),\n",
    "    output_type=RouterOutput,\n",
    ")\n",
    "\n",
    "agent_writer = Agent(\n",
    "    \"openai:gpt-4.1-mini\",\n",
    "    system_prompt=(\n",
    "        \"You are a writer. You will write an article about the topic provided.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "agent_toc = Agent(\n",
    "    \"openai:gpt-4.1-mini\",\n",
    "    system_prompt=(\n",
    "        \"You are an expert writer specialized in SEO. Provided with a topic, you will generate the table of contents for a short article.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "agent_reviewer = Agent(\n",
    "    \"openai:gpt-4.1-mini\",\n",
    "    system_prompt=(\n",
    "        \"You are a writer. You will review the article for the topic provided.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97be7efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@logfire.instrument(\"Run workflow\")\n",
    "def run_workflow(topic: str) -> str:\n",
    "    router_output = router_agent.run_sync(\n",
    "        f\"Classify the message: {topic}\"\n",
    "    )\n",
    "    category = router_output.output.category \n",
    "    if category == \"write_article\":\n",
    "        return agent_writer.run_sync(f\"Write an article about {topic}\").output\n",
    "    elif category == \"generate_table_of_contents\":\n",
    "        return agent_toc.run_sync(f\"Generate the table of contents of an article about {topic}\").output\n",
    "    else:\n",
    "        return agent_reviewer.run_sync(f\"Review the article for the topic {topic}\").output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc5511d",
   "metadata": {},
   "source": [
    "You can run the workflow and it will route your message and use the appropriate agent. For example, try to generate a table of contents for an article about AI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10fa652a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:08:05.547 Run workflow\n",
      "20:08:05.548   router_agent run\n",
      "20:08:05.549     chat gpt-4.1-mini\n",
      "20:08:06.810   agent_toc run\n",
      "20:08:06.811     chat gpt-4.1-mini\n"
     ]
    }
   ],
   "source": [
    "toc = run_workflow(\"Generate a table of contents for an article about AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff4cb977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table of Contents\n",
      "\n",
      "1. Introduction to Artificial Intelligence  \n",
      "2. History and Evolution of AI  \n",
      "3. Types of Artificial Intelligence  \n",
      "4. Key Technologies Behind AI  \n",
      "5. Applications of AI in Various Industries  \n",
      "6. Benefits and Challenges of AI  \n",
      "7. Future Trends in Artificial Intelligence  \n",
      "8. Ethical Considerations in AI Development  \n",
      "9. Conclusion\n"
     ]
    }
   ],
   "source": [
    "print(toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfcf0f0",
   "metadata": {},
   "source": [
    "Or, ask the workflow to review a social media post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49b09dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:08:08.917 Run workflow\n",
      "20:08:08.918   router_agent run\n",
      "20:08:08.919     chat gpt-4.1-mini\n",
      "20:08:09.691   agent_reviewer run\n",
      "20:08:09.692     chat gpt-4.1-mini\n"
     ]
    }
   ],
   "source": [
    "review = run_workflow(\"Review this post: 'There are times where there's no time, so you don't have time to write an article about it.'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a039b19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The post \"There are times where there's no time, so you don't have time to write an article about it.\" offers a succinct reflection on the challenges of time constraints, especially in tasks like writing. Its brevity captures the irony of not having enough time to address a situation—in this case, the lack of time itself. The message resonates with anyone who has felt overwhelmed by deadlines or competing priorities.\n",
      "\n",
      "However, as a piece intended for a broader audience or a formal article, it could benefit from expansion. Elaborating on scenarios where time scarcity impacts productivity, or providing strategies for managing pressing tasks despite limited time, would add depth and practical value. Additionally, refining the sentence for clarity and flow could enhance its impact—for example: \"Sometimes, we're so pressed for time that we can't even write about the very pressure we're under.\"\n",
      "\n",
      "In summary, the post effectively conveys a common frustration with time limitations in a clever and relatable way but serves better as a starting point for a more detailed discussion rather than a standalone article.\n"
     ]
    }
   ],
   "source": [
    "print(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be7735b",
   "metadata": {},
   "source": [
    "That's all!\n",
    "\n",
    "You can access this notebook [here](https://github.com/dylanjcastillo/blog/tree/main/til/router-pydantic-ai.ipynb).\n",
    "\n",
    "If you have any questions or feedback, please let me know in the comments below."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
