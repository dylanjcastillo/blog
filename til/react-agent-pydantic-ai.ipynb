{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b9ac1d5",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Using Pydantic AI to build a ReAct agent\"\n",
    "date: 2025-07-04\n",
    "description-meta: \"Using Pydantic AI to build a ReAct agent.\"\n",
    "categories:\n",
    "  - til\n",
    "  - llm\n",
    "  - pydantic-ai\n",
    "  - agents\n",
    "fig-cap-location: bottom \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5c3bca",
   "metadata": {},
   "source": [
    "I wanted to get more familiar with Pydantic AI, so I decided to build a ReAct agent with multiple tools.\n",
    "\n",
    "After a first failed attempt, I realized that Pydantic AI uses asyncio under the hood, so you need to enable `nest_asyncio` to use it in a notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce750c5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a607486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5193cf3",
   "metadata": {},
   "source": [
    "Then, I did the imports as usual. I hadn't used `logfire` for monitoring LLM applications before, so I thought it'd be a good idea to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4081c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Literal\n",
    "\n",
    "import logfire\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e5695",
   "metadata": {},
   "source": [
    "PydanticAI instrumentation uses OpenTelemetry (OTel). So it's pretty straightforward to use it with Logfire or with any other OTel-compatible observability tool.\n",
    "\n",
    "You just need to create a project in Logfire, generate a `Write token` and add it to the `.env` file. Then, you just need to run: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014a1f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "logfire.configure(\n",
    "    token=os.getenv('LOGFIRE_TOKEN'),\n",
    ")\n",
    "logfire.instrument_pydantic_ai()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a02dc0",
   "metadata": {},
   "source": [
    "This will ask you to select a project the first time you run it. It will generate a `logfire_credentials.json` file in your working directory. In following runs, it will automatically use the credentials from the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c8cc51",
   "metadata": {},
   "source": [
    "## ReAct Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edbf064",
   "metadata": {},
   "source": [
    "I decided to make an agent that had access to a tool to get the weather and another one that checks if the response that's going to be sent to the user follows the company guidelines.\n",
    "\n",
    "Here's thee code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4edf351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:57:42.206 react_agent run\n",
      "18:57:42.208   chat gpt-4.1-mini\n",
      "18:57:43.191   running 1 tool\n",
      "18:57:43.192     running tool: get_weather\n",
      "18:57:43.408   chat gpt-4.1-mini\n",
      "18:57:44.117   running 1 tool\n",
      "18:57:44.118     running tool: check_guidelines\n",
      "18:57:44.120       evaluator_agent run\n",
      "18:57:44.120         chat gpt-4.1-mini\n",
      "18:57:46.291   chat gpt-4.1-mini\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Feedback(BaseModel):\n",
    "    feedback: str\n",
    "    status: Literal['OK', 'REQUIRES FIXING']\n",
    "\n",
    "evaluator_agent = Agent(\n",
    "    'openai:gpt-4.1-mini',\n",
    "    system_prompt=(\n",
    "        \"You're a helpful assistant. Your task is to check if a given response follows the company guidelines. The company guidelines are that responses should be written in the style of a haiku. You should reply with 'OK' or 'REQUIRES FIXING' and a short explanation.\"\n",
    "    ),\n",
    "    output_type=Feedback,\n",
    ")\n",
    "\n",
    "react_agent = Agent(  \n",
    "    'openai:gpt-4.1-mini',\n",
    "    system_prompt=(\n",
    "        \"You're a helpful assistant. Use the tools provided when relevant. Then draft a response and check if it follows the company guidelines. Only respond to the user after you've validated and modified the response if needed.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "@react_agent.tool_plain\n",
    "def get_weather(latitude: float, longitude: float) -> str:\n",
    "    \"\"\"Get the weather of a given latitude and longitude\"\"\"\n",
    "    response = requests.get(\n",
    "        f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\"\n",
    "    )\n",
    "    data = response.json()\n",
    "    return str(data[\"current\"][\"temperature_2m\"])\n",
    "\n",
    "\n",
    "@react_agent.tool_plain\n",
    "def check_guidelines(drafted_response: str) -> str:\n",
    "    \"\"\"Check if a given response follows the company guidelines\"\"\"\n",
    "    response = evaluator_agent.run_sync(drafted_response)\n",
    "    return response.output\n",
    "\n",
    "\n",
    "response = react_agent.run_sync(\"What is the temperature in Madrid?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c618be",
   "metadata": {},
   "source": [
    "And here's the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d74111c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Madrid sunshine,\n",
      "Temperature climbs so high,\n",
      "Thirty-four degrees.\n"
     ]
    }
   ],
   "source": [
    "print(response.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52192f2b",
   "metadata": {},
   "source": [
    "The output in Logfire looks like typical observability tools:\n",
    "\n",
    "::: {#fig-logfire layout-ncol=3}\n",
    "![](./images/react-agent-logfire-1.png){.lightbox}\n",
    "\n",
    "![](./images/react-agent-logfire-2.png){.lightbox}\n",
    "\n",
    "![](./images/react-agent-logfire-3.png){.lightbox}\n",
    "\n",
    "Traces in Logfire\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be7735b",
   "metadata": {},
   "source": [
    "That's all!\n",
    "\n",
    "You can access this notebook [here](https://github.com/dylanjcastillo/blog/tree/main/til/react-agent-pydantic-ai.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
