{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Is Pydantic making your model dumber?\"\n",
    "date: \"11/10/2024\"\n",
    "date-modified: last-modified\n",
    "description-meta: \"\"\n",
    "toc: true\n",
    "toc-depth: 3\n",
    "lightbox: true\n",
    "fig-cap-location: margin\n",
    "categories:\n",
    "  - llm\n",
    "  - openai\n",
    "  - pydantic\n",
    "  - python\n",
    "author:\n",
    "  - name: Dylan Castillo\n",
    "    url: https://dylancastillo.co\n",
    "    affiliation: Iwana Labs\n",
    "    affiliation-url: https://iwanalabs.com\n",
    "citation: true\n",
    "comments:\n",
    "  utterances:\n",
    "    repo: dylanjcastillo/blog_comments\n",
    "    theme: dark-blue\n",
    "    issue-term: pathname\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, start by importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dcast/Documents/GitHub/blog/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import difflib\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from asyncio import Semaphore\n",
    "from enum import Enum\n",
    "from itertools import permutations\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import instructor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "from openai import AsyncOpenAI\n",
    "from openai.types.chat import ChatCompletion\n",
    "from pydantic import BaseModel, Field\n",
    "from scipy import stats\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "langsmith_client = wrap_openai(AsyncOpenAI())\n",
    "instructor_client = instructor.from_openai(langsmith_client, mode=instructor.Mode.TOOLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path().absolute().parent / \"data\" / \"live_bench\"\n",
    "reasoning_dir = data_dir / \"reasoning\"\n",
    "math_dir = data_dir / \"math\"\n",
    "language_dir = data_dir / \"language\"\n",
    "\n",
    "df_reasoning = pd.read_json(reasoning_dir / \"updated_questions.jsonl\", lines=True)\n",
    "df_language = pd.read_json(language_dir / \"updated_questions.jsonl\", lines=True)\n",
    "df_math = pd.read_json(math_dir / \"updated_questions.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Response(BaseModel):\n",
    "    reasoning: str = Field(description=\"Your reasoning explaining your answer.\")\n",
    "    answer: str = Field(description=\"Your answer, don't include any other text.\")\n",
    "\n",
    "\n",
    "class PromptType(Enum):\n",
    "    WITHOUT_STRUCTURED_OUTPUT = \"without_structured_output\"\n",
    "    WITH_TOOL_CALLS = \"with_structured_output_tool_calls\"\n",
    "    WITH_JSON_MODE = \"with_structured_output_json_mode\"\n",
    "\n",
    "\n",
    "SYSTEM_MESSAGE_MAPPING = {\n",
    "    PromptType.WITHOUT_STRUCTURED_OUTPUT.value: (\n",
    "        \"You're a helpful assistant. You will help me answer a question.\"\n",
    "        \"\\nYou must respond using the following format:\"\n",
    "        \"\\nREASONING: <your reasoning explaining your answer>\"\n",
    "        \"\\nANSWER: <your answer, don't include any other text>\"\n",
    "    ),\n",
    "    PromptType.WITH_TOOL_CALLS.value: (\n",
    "        \"You're a helpful assistant. You will help me answer a question.\"\n",
    "    ),\n",
    "    PromptType.WITH_JSON_MODE.value: (\n",
    "        \"You're a helpful assistant. You will help me answer a question.\"\n",
    "        + \"\\nYou must respond using the following JSON schema:\"\n",
    "        + json.dumps(Response.model_json_schema())\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(\n",
    "    response: ChatCompletion | Response, response_type: PromptType\n",
    ") -> str:\n",
    "    if isinstance(response, Response):\n",
    "        return response.answer\n",
    "    elif (\n",
    "        isinstance(response, ChatCompletion)\n",
    "        and response_type == PromptType.WITHOUT_STRUCTURED_OUTPUT\n",
    "    ):\n",
    "        return response.choices[0].message.content.split(\"\\nANSWER:\")[1].strip()\n",
    "    elif (\n",
    "        isinstance(response, ChatCompletion)\n",
    "        and response_type == PromptType.WITH_JSON_MODE\n",
    "    ):\n",
    "        return Response.model_validate_json(response.choices[0].message.content).answer\n",
    "    raise ValueError(f\"Invalid response type: {type(response)}\")\n",
    "\n",
    "\n",
    "@traceable\n",
    "async def call_model(\n",
    "    client,\n",
    "    prompt_type: PromptType,\n",
    "    user_message: str,\n",
    "    timeout: int = 120,\n",
    ") -> Response:\n",
    "    params = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_MESSAGE_MAPPING[prompt_type.value]},\n",
    "            {\"role\": \"user\", \"content\": user_message},\n",
    "        ],\n",
    "        \"timeout\": timeout,\n",
    "    }\n",
    "    if prompt_type == PromptType.WITH_JSON_MODE:\n",
    "        params.update({\"response_format\": {\"type\": \"json_object\"}})\n",
    "    if prompt_type == PromptType.WITH_TOOL_CALLS:\n",
    "        params.update(\n",
    "            {\n",
    "                \"response_model\": Response,\n",
    "            }\n",
    "        )\n",
    "    response = await client.chat.completions.create(**params)\n",
    "    return parse_response(response, prompt_type)\n",
    "\n",
    "\n",
    "@traceable\n",
    "async def process_row(\n",
    "    row: pd.Series,\n",
    "    prompt_type: PromptType,\n",
    "    semaphore: Semaphore,\n",
    ") -> str:\n",
    "    async with semaphore:\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                answer = await call_model(\n",
    "                    client=(\n",
    "                        instructor_client\n",
    "                        if prompt_type == PromptType.WITH_TOOL_CALLS\n",
    "                        else langsmith_client\n",
    "                    ),\n",
    "                    prompt_type=prompt_type,\n",
    "                    user_message=f\"Question:\\n{row.updated_question}\",\n",
    "                )\n",
    "                return answer\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row {row.name}: {e}\")\n",
    "                continue\n",
    "        raise Exception(f\"Failed to process row {row.name}, after 3 attempts\")\n",
    "\n",
    "\n",
    "@traceable\n",
    "async def process_df(\n",
    "    df: pd.DataFrame,\n",
    "    prompt_type: PromptType,\n",
    "    concurrency: int = 100,\n",
    ") -> List[str]:\n",
    "    semaphore = Semaphore(concurrency)\n",
    "    tasks = [process_row(row, prompt_type, semaphore) for _, row in df.iterrows()]\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from:\n",
    "# https://github.com/LiveBench/LiveBench/blob/main/livebench/process_results/writing/plot_unscrambling/utils.py\n",
    "def levenshtein_distance(A, B):\n",
    "    N, M = len(A), len(B)\n",
    "    # Create an array of size NxM\n",
    "    dp = [[0 for i in range(M + 1)] for j in range(N + 1)]\n",
    "\n",
    "    # Base Case: When N = 0\n",
    "    for j in range(M + 1):\n",
    "        dp[0][j] = j\n",
    "    # Base Case: When M = 0\n",
    "    for i in range(N + 1):\n",
    "        dp[i][0] = i\n",
    "    # Transitions\n",
    "    for i in range(1, N + 1):\n",
    "        for j in range(1, M + 1):\n",
    "            if A[i - 1] == B[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(\n",
    "                    dp[i - 1][j],  # Insertion\n",
    "                    dp[i][j - 1],  # Deletion\n",
    "                    dp[i - 1][j - 1],  # Replacement\n",
    "                )\n",
    "\n",
    "    return dp[N][M]\n",
    "\n",
    "\n",
    "def plot_unscrambling_process_results(ground_truth: str, llm_answer: str) -> float:\n",
    "    gt_sentences = [s.strip() for s in ground_truth.split(\".\")]\n",
    "    ans_sentences = [s.strip() for s in llm_answer.split(\".\")]\n",
    "\n",
    "    gt_sentences = [s for s in gt_sentences if s]\n",
    "    ans_sentences = [s for s in ans_sentences if s]\n",
    "\n",
    "    ans_ordering = []\n",
    "    for x in gt_sentences:\n",
    "        best_match = difflib.get_close_matches(x, ans_sentences, n=1, cutoff=0.0)\n",
    "        if best_match:\n",
    "            ans_ordering.append(ans_sentences.index(best_match[0]))\n",
    "\n",
    "    n_sentences_gt = len(gt_sentences)\n",
    "    raw_distance = levenshtein_distance(list(range(len(gt_sentences))), ans_ordering)\n",
    "    score = 1 - (raw_distance / n_sentences_gt)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def evaluate_language_task(ground_truth: str, task_type: str, response: str):\n",
    "    if task_type == \"connections\":\n",
    "        objects = [\n",
    "            re.sub(r\"[^\\w\\s]\", \"\", o.strip().lower()) for o in response.split(\",\")\n",
    "        ]\n",
    "        gt_objects = [\n",
    "            re.sub(r\"[^\\w\\s]\", \"\", o.strip().lower()) for o in ground_truth.split(\",\")\n",
    "        ]\n",
    "\n",
    "        groups = [set(objects[i : i + 4]) for i in range(0, len(objects), 4)]\n",
    "        gt_groups = [set(gt_objects[i : i + 4]) for i in range(0, len(gt_objects), 4)]\n",
    "\n",
    "        max_correct = 0\n",
    "        for perm in permutations(groups):\n",
    "            correct_groups = sum(g1 == g2 for g1, g2 in zip(perm, gt_groups))\n",
    "            max_correct = max(max_correct, correct_groups)\n",
    "        return max_correct / len(gt_groups)\n",
    "    elif task_type == \"plot_unscrambling\":\n",
    "        return plot_unscrambling_process_results(ground_truth, response)\n",
    "    elif task_type == \"typos\":\n",
    "        return ground_truth in response\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid task type: {task_type}\")\n",
    "\n",
    "\n",
    "def evaluate_reasoning_task(ground_truth: str, task_type: str, response: str):\n",
    "    if task_type == \"web_of_lies_v2\":\n",
    "        response_objects = [\n",
    "            re.sub(r\"[^\\w\\s]\", \"\", o.strip().lower()) for o in response.split(\",\")\n",
    "        ]\n",
    "        gt_objects = [\n",
    "            re.sub(r\"[^\\w\\s]\", \"\", o.strip().lower()) for o in ground_truth.split(\",\")\n",
    "        ]\n",
    "        return response_objects == gt_objects\n",
    "    elif task_type in (\"spatial\", \"zebra_puzzle\"):\n",
    "        response = response.rstrip(\".\")\n",
    "        return ground_truth.lower().strip() == response.lower().strip()\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid task type: {task_type}\")\n",
    "\n",
    "\n",
    "def evaluate_math_task(ground_truth: str, task_type: str, response: str):\n",
    "    if task_type == \"olympiad\":\n",
    "        response_objects = [\n",
    "            re.sub(r\"[^\\w\\s]\", \"\", o.strip().lower()) for o in response.split(\",\")\n",
    "        ]\n",
    "        gt_objects = [\n",
    "            re.sub(r\"[^\\w\\s]\", \"\", o.strip().lower()) for o in ground_truth.split(\",\")\n",
    "        ]\n",
    "        return response_objects == gt_objects\n",
    "    elif task_type == \"math_comp\":\n",
    "        return ground_truth == response\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid task type: {task_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "def generate_outputs(df):\n",
    "    df_copy = df.copy()\n",
    "    responses_without_so = asyncio.run(\n",
    "        process_df(df_copy, PromptType.WITHOUT_STRUCTURED_OUTPUT)\n",
    "    )\n",
    "    responses_with_so_tool_calls = asyncio.run(\n",
    "        process_df(df_copy, PromptType.WITH_TOOL_CALLS)\n",
    "    )\n",
    "    responses_with_so_json_mode = asyncio.run(\n",
    "        process_df(df_copy, PromptType.WITH_JSON_MODE)\n",
    "    )\n",
    "    df_copy[\"response_without_so\"] = responses_without_so\n",
    "    df_copy[\"response_with_so_tool_calls\"] = responses_with_so_tool_calls\n",
    "    df_copy[\"response_with_so_json_mode\"] = responses_with_so_json_mode\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "def evaluate_outputs(df, evaluator):\n",
    "    df_copy = df.copy()\n",
    "    df_copy[\"score_without_so\"] = df_copy.apply(\n",
    "        lambda row: evaluator(\n",
    "            row[\"ground_truth\"], row[\"task\"], row[\"response_without_so\"]\n",
    "        ) * 1,\n",
    "        axis=1,\n",
    "    )\n",
    "    df_copy[\"score_with_so_tool_calls\"] = df_copy.apply(\n",
    "        lambda row: evaluator(\n",
    "            row[\"ground_truth\"], row[\"task\"], row[\"response_with_so_tool_calls\"]\n",
    "        ) * 1,\n",
    "        axis=1,\n",
    "    )\n",
    "    df_copy[\"score_with_so_json_mode\"] = df_copy.apply(\n",
    "        lambda row: evaluator(\n",
    "            row[\"ground_truth\"], row[\"task\"], row[\"response_with_so_json_mode\"]\n",
    "        ) * 1,\n",
    "        axis=1,\n",
    "    )\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reasoning_results = generate_outputs(df_reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reasoning_results = evaluate_outputs(df_reasoning_results, evaluate_reasoning_task)\n",
    "df_reasoning_results.to_csv(data_dir / \"reasoning\" / \"reasoning_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_questions</th>\n",
       "      <th>score_without_so</th>\n",
       "      <th>score_with_so_tool_calls</th>\n",
       "      <th>score_with_so_json_mode</th>\n",
       "      <th>elapsed_time_without_so_p50</th>\n",
       "      <th>elapsed_time_with_so_tool_calls_p50</th>\n",
       "      <th>elapsed_time_with_so_json_mode_p50</th>\n",
       "      <th>elapsed_time_without_so_p99</th>\n",
       "      <th>elapsed_time_with_so_tool_calls_p99</th>\n",
       "      <th>elapsed_time_with_so_json_mode_p99</th>\n",
       "      <th>elapsed_time_without_so_max</th>\n",
       "      <th>elapsed_time_with_so_tool_calls_max</th>\n",
       "      <th>elapsed_time_with_so_json_mode_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spatial</th>\n",
       "      <td>50</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.44</td>\n",
       "      <td>6.309775</td>\n",
       "      <td>5.758013</td>\n",
       "      <td>5.291537</td>\n",
       "      <td>21.688894</td>\n",
       "      <td>14.160294</td>\n",
       "      <td>16.911668</td>\n",
       "      <td>26.070317</td>\n",
       "      <td>14.635145</td>\n",
       "      <td>17.563303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>web_of_lies_v2</th>\n",
       "      <td>50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.48</td>\n",
       "      <td>23.556100</td>\n",
       "      <td>25.448873</td>\n",
       "      <td>16.081478</td>\n",
       "      <td>33.850377</td>\n",
       "      <td>37.454179</td>\n",
       "      <td>22.355108</td>\n",
       "      <td>34.307903</td>\n",
       "      <td>39.952389</td>\n",
       "      <td>22.828892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zebra_puzzle</th>\n",
       "      <td>50</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>15.259360</td>\n",
       "      <td>13.891867</td>\n",
       "      <td>10.480265</td>\n",
       "      <td>32.695507</td>\n",
       "      <td>23.824518</td>\n",
       "      <td>26.589262</td>\n",
       "      <td>33.320583</td>\n",
       "      <td>26.188481</td>\n",
       "      <td>29.870442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                n_questions  score_without_so  score_with_so_tool_calls  \\\n",
       "task                                                                      \n",
       "spatial                  50              0.44                      0.48   \n",
       "web_of_lies_v2           50              0.52                      0.40   \n",
       "zebra_puzzle             50              0.32                      0.30   \n",
       "\n",
       "                score_with_so_json_mode  elapsed_time_without_so_p50  \\\n",
       "task                                                                   \n",
       "spatial                            0.44                     6.309775   \n",
       "web_of_lies_v2                     0.48                    23.556100   \n",
       "zebra_puzzle                       0.40                    15.259360   \n",
       "\n",
       "                elapsed_time_with_so_tool_calls_p50  \\\n",
       "task                                                  \n",
       "spatial                                    5.758013   \n",
       "web_of_lies_v2                            25.448873   \n",
       "zebra_puzzle                              13.891867   \n",
       "\n",
       "                elapsed_time_with_so_json_mode_p50  \\\n",
       "task                                                 \n",
       "spatial                                   5.291537   \n",
       "web_of_lies_v2                           16.081478   \n",
       "zebra_puzzle                             10.480265   \n",
       "\n",
       "                elapsed_time_without_so_p99  \\\n",
       "task                                          \n",
       "spatial                           21.688894   \n",
       "web_of_lies_v2                    33.850377   \n",
       "zebra_puzzle                      32.695507   \n",
       "\n",
       "                elapsed_time_with_so_tool_calls_p99  \\\n",
       "task                                                  \n",
       "spatial                                   14.160294   \n",
       "web_of_lies_v2                            37.454179   \n",
       "zebra_puzzle                              23.824518   \n",
       "\n",
       "                elapsed_time_with_so_json_mode_p99  \\\n",
       "task                                                 \n",
       "spatial                                  16.911668   \n",
       "web_of_lies_v2                           22.355108   \n",
       "zebra_puzzle                             26.589262   \n",
       "\n",
       "                elapsed_time_without_so_max  \\\n",
       "task                                          \n",
       "spatial                           26.070317   \n",
       "web_of_lies_v2                    34.307903   \n",
       "zebra_puzzle                      33.320583   \n",
       "\n",
       "                elapsed_time_with_so_tool_calls_max  \\\n",
       "task                                                  \n",
       "spatial                                   14.635145   \n",
       "web_of_lies_v2                            39.952389   \n",
       "zebra_puzzle                              26.188481   \n",
       "\n",
       "                elapsed_time_with_so_json_mode_max  \n",
       "task                                                \n",
       "spatial                                  17.563303  \n",
       "web_of_lies_v2                           22.828892  \n",
       "zebra_puzzle                             29.870442  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "df_reasoning_results.groupby(\"task\").agg(\n",
    "    n_questions=(\"question_id\", \"count\"),\n",
    "    score_without_so=(\"score_without_so\", \"mean\"),\n",
    "    score_with_so_tool_calls=(\"score_with_so_tool_calls\", \"mean\"),\n",
    "    score_with_so_json_mode=(\"score_with_so_json_mode\", \"mean\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_language_results = generate_outputs(df_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_language_results = evaluate_outputs(df_language_results, evaluate_language_task)\n",
    "df_language_results.to_csv(data_dir / \"language\" / \"language_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_questions</th>\n",
       "      <th>score_without_so</th>\n",
       "      <th>score_with_so_tool_calls</th>\n",
       "      <th>score_with_so_json_mode</th>\n",
       "      <th>elapsed_time_without_so_p50</th>\n",
       "      <th>elapsed_time_with_so_tool_calls_p50</th>\n",
       "      <th>elapsed_time_with_so_json_mode_p50</th>\n",
       "      <th>elapsed_time_without_so_p99</th>\n",
       "      <th>elapsed_time_with_so_tool_calls_p99</th>\n",
       "      <th>elapsed_time_with_so_json_mode_p99</th>\n",
       "      <th>elapsed_time_without_so_max</th>\n",
       "      <th>elapsed_time_with_so_tool_calls_max</th>\n",
       "      <th>elapsed_time_with_so_json_mode_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>connections</th>\n",
       "      <td>50</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>0.448333</td>\n",
       "      <td>26.431623</td>\n",
       "      <td>27.048912</td>\n",
       "      <td>24.045916</td>\n",
       "      <td>38.849826</td>\n",
       "      <td>40.733236</td>\n",
       "      <td>30.271607</td>\n",
       "      <td>40.925307</td>\n",
       "      <td>41.868820</td>\n",
       "      <td>30.432643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plot_unscrambling</th>\n",
       "      <td>40</td>\n",
       "      <td>0.361738</td>\n",
       "      <td>0.333854</td>\n",
       "      <td>0.347735</td>\n",
       "      <td>25.695105</td>\n",
       "      <td>25.504034</td>\n",
       "      <td>20.316156</td>\n",
       "      <td>46.584709</td>\n",
       "      <td>51.921579</td>\n",
       "      <td>38.502521</td>\n",
       "      <td>48.360810</td>\n",
       "      <td>54.453975</td>\n",
       "      <td>39.024707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>typos</th>\n",
       "      <td>50</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>6.360404</td>\n",
       "      <td>7.692957</td>\n",
       "      <td>9.245303</td>\n",
       "      <td>14.516300</td>\n",
       "      <td>20.595285</td>\n",
       "      <td>50.410145</td>\n",
       "      <td>18.563140</td>\n",
       "      <td>22.796652</td>\n",
       "      <td>50.561014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   n_questions  score_without_so  score_with_so_tool_calls  \\\n",
       "task                                                                         \n",
       "connections                 50          0.480000                  0.406667   \n",
       "plot_unscrambling           40          0.361738                  0.333854   \n",
       "typos                       50          0.600000                  0.580000   \n",
       "\n",
       "                   score_with_so_json_mode  elapsed_time_without_so_p50  \\\n",
       "task                                                                      \n",
       "connections                       0.448333                    26.431623   \n",
       "plot_unscrambling                 0.347735                    25.695105   \n",
       "typos                             0.580000                     6.360404   \n",
       "\n",
       "                   elapsed_time_with_so_tool_calls_p50  \\\n",
       "task                                                     \n",
       "connections                                  27.048912   \n",
       "plot_unscrambling                            25.504034   \n",
       "typos                                         7.692957   \n",
       "\n",
       "                   elapsed_time_with_so_json_mode_p50  \\\n",
       "task                                                    \n",
       "connections                                 24.045916   \n",
       "plot_unscrambling                           20.316156   \n",
       "typos                                        9.245303   \n",
       "\n",
       "                   elapsed_time_without_so_p99  \\\n",
       "task                                             \n",
       "connections                          38.849826   \n",
       "plot_unscrambling                    46.584709   \n",
       "typos                                14.516300   \n",
       "\n",
       "                   elapsed_time_with_so_tool_calls_p99  \\\n",
       "task                                                     \n",
       "connections                                  40.733236   \n",
       "plot_unscrambling                            51.921579   \n",
       "typos                                        20.595285   \n",
       "\n",
       "                   elapsed_time_with_so_json_mode_p99  \\\n",
       "task                                                    \n",
       "connections                                 30.271607   \n",
       "plot_unscrambling                           38.502521   \n",
       "typos                                       50.410145   \n",
       "\n",
       "                   elapsed_time_without_so_max  \\\n",
       "task                                             \n",
       "connections                          40.925307   \n",
       "plot_unscrambling                    48.360810   \n",
       "typos                                18.563140   \n",
       "\n",
       "                   elapsed_time_with_so_tool_calls_max  \\\n",
       "task                                                     \n",
       "connections                                  41.868820   \n",
       "plot_unscrambling                            54.453975   \n",
       "typos                                        22.796652   \n",
       "\n",
       "                   elapsed_time_with_so_json_mode_max  \n",
       "task                                                   \n",
       "connections                                 30.432643  \n",
       "plot_unscrambling                           39.024707  \n",
       "typos                                       50.561014  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "df_language_results.groupby(\"task\").agg(\n",
    "    n_questions=(\"question_id\", \"count\"),\n",
    "    score_without_so=(\"score_without_so\", \"mean\"),\n",
    "    score_with_so_tool_calls=(\"score_with_so_tool_calls\", \"mean\"),\n",
    "    score_with_so_json_mode=(\"score_with_so_json_mode\", \"mean\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row 105: list index out of range\n",
      "Error processing row 113: 1 validation error for Response\n",
      "answer\n",
      "  Field required [type=missing, input_value={'reasoning': 'The soluti...NLOCKED_MODIFIER': True}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n"
     ]
    }
   ],
   "source": [
    "df_math_results = generate_outputs(df_math)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_math_results = evaluate_outputs(df_math_results, evaluate_math_task)\n",
    "df_math_results.to_csv(data_dir / \"math\" / \"math_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_questions</th>\n",
       "      <th>score_without_so</th>\n",
       "      <th>score_with_so_tool_calls</th>\n",
       "      <th>score_with_so_json_mode</th>\n",
       "      <th>elapsed_time_without_so_p50</th>\n",
       "      <th>elapsed_time_with_so_tool_calls_p50</th>\n",
       "      <th>elapsed_time_with_so_json_mode_p50</th>\n",
       "      <th>elapsed_time_without_so_p99</th>\n",
       "      <th>elapsed_time_with_so_tool_calls_p99</th>\n",
       "      <th>elapsed_time_with_so_json_mode_p99</th>\n",
       "      <th>elapsed_time_without_so_max</th>\n",
       "      <th>elapsed_time_with_so_tool_calls_max</th>\n",
       "      <th>elapsed_time_with_so_json_mode_max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>math_comp</th>\n",
       "      <td>96</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.385417</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>17.434276</td>\n",
       "      <td>18.396737</td>\n",
       "      <td>11.845642</td>\n",
       "      <td>31.977144</td>\n",
       "      <td>33.291323</td>\n",
       "      <td>37.755325</td>\n",
       "      <td>39.439779</td>\n",
       "      <td>38.248845</td>\n",
       "      <td>42.578924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olympiad</th>\n",
       "      <td>36</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>32.917217</td>\n",
       "      <td>33.718626</td>\n",
       "      <td>24.595792</td>\n",
       "      <td>42.860183</td>\n",
       "      <td>67.166222</td>\n",
       "      <td>66.068712</td>\n",
       "      <td>43.268417</td>\n",
       "      <td>74.609720</td>\n",
       "      <td>76.681866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           n_questions  score_without_so  score_with_so_tool_calls  \\\n",
       "task                                                                 \n",
       "math_comp           96          0.343750                  0.385417   \n",
       "olympiad            36          0.361111                  0.333333   \n",
       "\n",
       "           score_with_so_json_mode  elapsed_time_without_so_p50  \\\n",
       "task                                                              \n",
       "math_comp                 0.354167                    17.434276   \n",
       "olympiad                  0.305556                    32.917217   \n",
       "\n",
       "           elapsed_time_with_so_tool_calls_p50  \\\n",
       "task                                             \n",
       "math_comp                            18.396737   \n",
       "olympiad                             33.718626   \n",
       "\n",
       "           elapsed_time_with_so_json_mode_p50  elapsed_time_without_so_p99  \\\n",
       "task                                                                         \n",
       "math_comp                           11.845642                    31.977144   \n",
       "olympiad                            24.595792                    42.860183   \n",
       "\n",
       "           elapsed_time_with_so_tool_calls_p99  \\\n",
       "task                                             \n",
       "math_comp                            33.291323   \n",
       "olympiad                             67.166222   \n",
       "\n",
       "           elapsed_time_with_so_json_mode_p99  elapsed_time_without_so_max  \\\n",
       "task                                                                         \n",
       "math_comp                           37.755325                    39.439779   \n",
       "olympiad                            66.068712                    43.268417   \n",
       "\n",
       "           elapsed_time_with_so_tool_calls_max  \\\n",
       "task                                             \n",
       "math_comp                            38.248845   \n",
       "olympiad                             74.609720   \n",
       "\n",
       "           elapsed_time_with_so_json_mode_max  \n",
       "task                                           \n",
       "math_comp                           42.578924  \n",
       "olympiad                            76.681866  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "\n",
    "df_math_results.groupby(\"task\").agg(\n",
    "    n_questions=(\"question_id\", \"count\"),\n",
    "    score_without_so=(\"score_without_so\", \"mean\"),\n",
    "    score_with_so_tool_calls=(\"score_with_so_tool_calls\", \"mean\"),\n",
    "    score_with_so_json_mode=(\"score_with_so_json_mode\", \"mean\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | output: false\n",
    "def calculate_confidence_intervals(df):\n",
    "    mean_score_without_so = df[\"score_without_so\"].mean()\n",
    "    mean_score_with_so_tool_calls = df[\"score_with_so_tool_calls\"].mean()\n",
    "    mean_score_with_so_json_mode = df[\"score_with_so_json_mode\"].mean()\n",
    "\n",
    "    n = len(df)\n",
    "    se_score_without_so = df[\"score_without_so\"].std() / np.sqrt(n)\n",
    "    se_score_with_so_tool_calls = df[\"score_with_so_tool_calls\"].std() / np.sqrt(n)\n",
    "    se_score_with_so_json_mode = df[\"score_with_so_json_mode\"].std() / np.sqrt(n)\n",
    "\n",
    "    ci_score_without_so = [\n",
    "        mean_score_without_so - 1.96 * se_score_without_so,\n",
    "        mean_score_without_so + 1.96 * se_score_without_so,\n",
    "    ]\n",
    "    ci_score_with_so_tool_calls = [\n",
    "        mean_score_with_so_tool_calls - 1.96 * se_score_with_so_tool_calls,\n",
    "        mean_score_with_so_tool_calls + 1.96 * se_score_with_so_tool_calls,\n",
    "    ]\n",
    "    ci_score_with_so_json_mode = [\n",
    "        mean_score_with_so_json_mode - 1.96 * se_score_with_so_json_mode,\n",
    "        mean_score_with_so_json_mode + 1.96 * se_score_with_so_json_mode,\n",
    "    ]\n",
    "\n",
    "    print(\n",
    "        f\"Response format without SO - Mean: {mean_score_without_so * 100:.2f}% CI: {ci_score_without_so[0] * 100:.2f}% - {ci_score_without_so[1] * 100:.2f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Response format with SO tool calls - Mean: {mean_score_with_so_tool_calls * 100:.2f}% CI: {ci_score_with_so_tool_calls[0] * 100:.2f}% - {ci_score_with_so_tool_calls[1] * 100:.2f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Response format with SO JSON mode - Mean: {mean_score_with_so_json_mode * 100:.2f}% CI: {ci_score_with_so_json_mode[0] * 100:.2f}% - {ci_score_with_so_json_mode[1] * 100:.2f}%\"\n",
    "    )\n",
    "\n",
    "\n",
    "def run_paired_t_test(df):\n",
    "    score_without_so = df[\"score_without_so\"] * 1\n",
    "    score_with_so_tool_calls = df[\"score_with_so_tool_calls\"] * 1\n",
    "    score_with_so_json_mode = df[\"score_with_so_json_mode\"] * 1\n",
    "\n",
    "    t_stat_without_so_tool_calls, p_value_without_so_tool_calls = stats.ttest_rel(\n",
    "        score_without_so, score_with_so_tool_calls\n",
    "    )\n",
    "    print(\"Without SO vs With SO Tool Calls\")\n",
    "    print(\n",
    "        f\"t-statistic: {t_stat_without_so_tool_calls}, p-value: {p_value_without_so_tool_calls}\"\n",
    "    )\n",
    "\n",
    "    t_stat_without_so_json_mode, p_value_without_so_json_mode = stats.ttest_rel(\n",
    "        score_without_so, score_with_so_json_mode\n",
    "    )\n",
    "    print(\"Without SO vs With SO JSON Mode\")\n",
    "    print(\n",
    "        f\"t-statistic: {t_stat_without_so_json_mode}, p-value: {p_value_without_so_json_mode}\"\n",
    "    )\n",
    "\n",
    "    print(\"With SO Tool Calls vs With SO JSON Mode\")\n",
    "    t_stat_with_so_tool_calls_json_mode, p_value_with_so_tool_calls_json_mode = (\n",
    "        stats.ttest_rel(score_with_so_tool_calls, score_with_so_json_mode)\n",
    "    )\n",
    "    print(\n",
    "        f\"t-statistic: {t_stat_with_so_tool_calls_json_mode}, p-value: {p_value_with_so_tool_calls_json_mode}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response format without SO - Mean: 42.67% CI: 34.73% - 50.61%\n",
      "Response format with SO tool calls - Mean: 39.33% CI: 31.49% - 47.18%\n",
      "Response format with SO JSON mode - Mean: 44.00% CI: 36.03% - 51.97%\n",
      "Without SO vs With SO Tool Calls\n",
      "t-statistic: 0.744246831182308, p-value: 0.4578992890783663\n",
      "Without SO vs With SO JSON Mode\n",
      "t-statistic: -0.28779122814116004, p-value: 0.7739064538761314\n",
      "With SO Tool Calls vs With SO JSON Mode\n",
      "t-statistic: -1.0000000000000002, p-value: 0.3189317446414372\n"
     ]
    }
   ],
   "source": [
    "calculate_confidence_intervals(df_reasoning_results)\n",
    "run_paired_t_test(df_reasoning_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response format without SO - Mean: 48.91% CI: 42.05% - 55.76%\n",
      "Response format with SO tool calls - Mean: 44.78% CI: 37.96% - 51.59%\n",
      "Response format with SO JSON mode - Mean: 46.66% CI: 40.03% - 53.30%\n",
      "Without SO vs With SO Tool Calls\n",
      "t-statistic: 1.2362091633273395, p-value: 0.21846571843131643\n",
      "Without SO vs With SO JSON Mode\n",
      "t-statistic: 0.7979403511518648, p-value: 0.42626620343526367\n",
      "With SO Tool Calls vs With SO JSON Mode\n",
      "t-statistic: -0.5662363791890643, p-value: 0.5721461676427859\n"
     ]
    }
   ],
   "source": [
    "calculate_confidence_intervals(df_language_results)\n",
    "run_paired_t_test(df_language_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response format without SO - Mean: 34.85% CI: 26.69% - 43.01%\n",
      "Response format with SO tool calls - Mean: 37.12% CI: 28.85% - 45.39%\n",
      "Response format with SO JSON mode - Mean: 34.09% CI: 25.97% - 42.21%\n",
      "Without SO vs With SO Tool Calls\n",
      "t-statistic: -0.5985396996906245, p-value: 0.5505134016336659\n",
      "Without SO vs With SO JSON Mode\n",
      "t-statistic: 0.19174662859148225, p-value: 0.8482375752451983\n",
      "With SO Tool Calls vs With SO JSON Mode\n",
      "t-statistic: 0.7833154780631507, p-value: 0.4348557497710035\n"
     ]
    }
   ],
   "source": [
    "calculate_confidence_intervals(df_math_results)\n",
    "run_paired_t_test(df_math_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the mean scores with confidence intervals:\n",
    "\n",
    "| **Category** | **Response Format**              | **Mean (CI %)**         |\n",
    "|--------------|----------------------------------|-------------------------|\n",
    "| **Reasoning** | Without SO                      | 42.67% (34.73 - 50.61)  |\n",
    "|               | With SO Tool Calls               | 39.33% (31.49 - 47.18)  |\n",
    "|               | With SO JSON Mode                | 44.00% (36.03 - 51.97)  |\n",
    "| **Language**  | Without SO                      | 48.91% (42.05 - 55.76)  |\n",
    "|               | With SO Tool Calls               | 44.78% (37.96 - 51.59)  |\n",
    "|               | With SO JSON Mode                | 46.66% (40.03 - 53.30)  |\n",
    "| **Math**      | Without SO                      | 34.85% (26.69 - 43.01)  |\n",
    "|               | With SO Tool Calls               | 37.12% (28.85 - 45.39)  |\n",
    "|               | With SO JSON Mode                | 34.09% (25.97 - 42.21)  |\n",
    "\n",
    "And these are the results of the paired t-tests:\n",
    "\n",
    "### 2. T-Test Results\n",
    "\n",
    "| **Category** | **Comparison**                         | **t-Statistic** | **p-Value** |\n",
    "|--------------|----------------------------------------|-----------------|-------------|\n",
    "| **Reasoning** | Without SO vs With SO Tool Calls       | 0.7442          | 0.4579      |\n",
    "|               | Without SO vs With SO JSON Mode        | -0.2878         | 0.7739      |\n",
    "|               | With SO Tool Calls vs With SO JSON Mode| -1.0000         | 0.3189      |\n",
    "| **Language**  | Without SO vs With SO Tool Calls       | 1.2362          | 0.2185      |\n",
    "|               | Without SO vs With SO JSON Mode        | 0.7979          | 0.4263      |\n",
    "|               | With SO Tool Calls vs With SO JSON Mode| -0.5662         | 0.5721      |\n",
    "| **Math**      | Without SO vs With SO Tool Calls       | -0.5985         | 0.5505      |\n",
    "|               | Without SO vs With SO JSON Mode        | 0.1917          | 0.8482      |\n",
    "|               | With SO Tool Calls vs With SO JSON Mode| 0.7833          | 0.4349      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
