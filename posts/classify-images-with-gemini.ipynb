{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Image Classification using Gemini\"\n",
    "date: \"10/08/2024\"\n",
    "date-modified: last-modified\n",
    "description-meta: \"Learn how to use In-Context Learning (ICL) to classify images using Gemini\"\n",
    "toc: true\n",
    "toc-depth: 3\n",
    "lightbox: true\n",
    "fig-cap-location: margin\n",
    "categories:\n",
    "  - mllms\n",
    "  - in-context-learning\n",
    "  - gemini\n",
    "author:\n",
    "  - name: Dylan Castillo\n",
    "    url: https://dylancastillo.co\n",
    "    affiliation: Iwana Labs\n",
    "    affiliation-url: https://iwanalabs.com\n",
    "    citation: true\n",
    "    comments:\n",
    "    utterances:\n",
    "    repo: dylanjcastillo/blog_comments\n",
    "    theme: dark-blue\n",
    "    issue-term: pathname\n",
    "draft: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One overlooked aspect of Multimodal Large Language Models (MLLMs) is the ability to use In-Context Learning (ICL) to classify images. This is a technique that allows the model to learn from a small number of ground truth images provided at inference time and make predictions on previously unseen images.\n",
    "\n",
    "I recently worked on a project for a client that made use of this approach, so I thought it'd be fun to write a short tutorial about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To follow this tutorial you'll need to:\n",
    "\n",
    "- Generate a key in [Google AI Studio](https://aistudio.google.com/app/apikey)\n",
    "- Download [Danish Fungi 2024 â€“ Mini dataset](https://github.com/BohemianVRA/DanishFungiDataset)\n",
    "- Create a virtual environment and install the requirements:\n",
    "\n",
    "```bash\n",
    "python -m venv venv\n",
    "source venv/bin/activate\n",
    "pip install pandas numpy scikit-learn nest-asyncio google-generativeai\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Gemini Flash 1.5?\n",
    "\n",
    "I'm going to use Gemini Flash 1.5 for three reasons:\n",
    "\n",
    "- It's a lot cheaper than [GPT-4o](https://platform.openai.com/pricing) and [Sonnet 3.5](https://docs.anthropic.com/en/docs/build-with-claude/vision#calculate-image-costs). For an image of 512x512 pixels, Gemini Flash 1.5 is 66x cheaper than Gemini Pro 1.5, 32x cheaper than GPT-4o, and 52x cheaper than Sonnet 3.5[^longnote].\n",
    "- It lets you use up to 3,000 images per request. By trial and error, I found that GPT-4o seems to have a hard limit at 250 images per request and Sonnet 3.5's documentation mentions a limit of 20 images per request.\n",
    "- It works well enough for this task. If you really want to squeeze the last bit of performance out of your model, you can use GPT-4o, Sonnet 3.5, or Gemini Pro 1.5.\n",
    "\n",
    "Regardless, of the model you choose, this tutorial will be a good starting point for you to classify images using ICL.\n",
    "\n",
    "[^longnote]: Estimated costs as of August 10, 2024:\n",
    "\n",
    "    | Model | Cost per 512x512 image |\n",
    "    |-------|------------------------|\n",
    "    | Gemini Flash 1.5 | $0.00002 |\n",
    "    | Gemini Pro 1.5 | $0.000064 |\n",
    "    | GPT-4o | $0.000638 |\n",
    "    | Sonnet 3.5 | $0.001047 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: false\n",
    "#| echo: false\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nest_asyncio` makes it possible to run async code in Jupyter notebooks. You can enable it in your notebook by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dcast/Documents/GitHub/blog/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import base64\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import google.generativeai as genai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display, HTML\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read dataframes and filter out non matching items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/\"\n",
    "metadata_dir = data_dir + \"DF20M-metadata/\"\n",
    "images_dir = data_dir + \"DF20M/\"\n",
    "\n",
    "df_train = pd.read_csv(metadata_dir + \"DanishFungi2024-Mini-train-subset.csv\")\n",
    "df_test = pd.read_csv(metadata_dir + \"DanishFungi2024-Mini-pubtest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 182)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | output: false\n",
    "# | echo: false\n",
    "# Check that the test and train dataframes have the same items\n",
    "assert (\n",
    "    df_test[\"class_id\"].isin(df_train[\"class_id\"]).all()\n",
    "), \"Test and train dataframes do not have the same items\"\n",
    "assert (\n",
    "    df_train[\"class_id\"].isin(df_test[\"class_id\"]).all()\n",
    "), \"Train and test dataframes do not have the same items\"\n",
    "\n",
    "df_test[\"class_id\"].nunique(), df_train[\"class_id\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create output dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode images\n",
    "df_train[\"full_image_path\"] = df_train[\"image_path\"].apply(lambda x: f\"{images_dir}{x.split('/')[-1]}\")\n",
    "df_test[\"full_image_path\"] = df_test[\"image_path\"].apply(lambda x: f\"{images_dir}{x.split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIER_SYSTEM_PROMPT = \"\"\"You are an expert mycologist specialized in classifying mushrooms from images. Your task is to match input images of mushrooms and assign a label based on the most similar context image (a picture of a mushroom). \n",
    "\n",
    "Provided with a list of context images and a list of input images, compare each input image to all context images and determine the best matching context image for each input image and assign a label and confidence score. \n",
    "\n",
    "Provide your output as a JSON object in the following format:\n",
    "\n",
    "{\n",
    "    \"number_of_classified_images\": <integer>,\n",
    "    \"output\": [\n",
    "        {\n",
    "            \"id\": <input_image_id>,\n",
    "            \"class_id\": <class_id>, \n",
    "            \"confidence\": <integer, between 0 and 10, the higher the more confident>\n",
    "        }, \n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "\n",
    "## Instructions \n",
    "\n",
    "1. Carefully examine each input image.\n",
    "2. Compare it to all context images.\n",
    "3. Determine the most similar context image and assign that label to the input image.\n",
    "4. Assign a confidence score between 0 and 10, where 10 indicates the highest confidence in the match.\n",
    "\n",
    "## Guidelines\n",
    "\n",
    "- ALWAYS produce valid JSON.\n",
    "- Generate ONLY a single prediction per input image. DO NOT produce duplicated predictions for any input image.\n",
    "- Make a prediction for ALL input images. If there's no matching label, classify it with the most similar label.\n",
    "- Each input image must be assigned a SINGLE label based on the context images. \n",
    "- You MUST only predict the context image labels provided. \n",
    "\n",
    "## Example\n",
    "\n",
    "Given these context images:\n",
    "\n",
    "```\n",
    "- <images from class 1>, class_id:class_1\n",
    "- <images from class 2>, class_id:class_2\n",
    "- <images from class 3>, class_id:class_3\n",
    "```\n",
    "\n",
    "These input images:\n",
    "```\n",
    "- <image to classify 1>, input_image_id:0\n",
    "- <image to classify 2>, input_image_id:1\n",
    "- <image to classify 3>, input_image_id:2\n",
    "- <image to classify 4>, input_image_id:3\n",
    "```\n",
    "\n",
    "And this total number of input images: 5\n",
    "\n",
    "This is an example of a valid output:\n",
    "```\n",
    "{\n",
    "  \"total_input_images\": 5,\n",
    "  \"output\": [\n",
    "      {\n",
    "        \"id\": \"0\",\n",
    "        \"confidence\": 10,\n",
    "        \"class_id\": \"class_2\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"1\",\n",
    "        \"confidence\": 9,\n",
    "        \"class_id\": \"class_3\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"2\",\n",
    "        \"confidence\": 4,\n",
    "        \"class_id\": \"class_3\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"3\",\n",
    "        \"confidence\": 2,\n",
    "        \"class_id\": \"class_1\"\n",
    "      },\n",
    "      {\n",
    "        \"id\": \"4\",\n",
    "        \"confidence\": 10,\n",
    "        \"class_id\": \"class_2\"\n",
    "      }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"application/json\",\n",
    "}\n",
    "classification_model = genai.GenerativeModel(\n",
    "    \"gemini-1.5-flash-exp-0827\", \n",
    "    system_instruction=CLASSIFIER_SYSTEM_PROMPT, \n",
    "    generation_config=generation_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_subset = df_test[df_test.class_id.isin([2, 50, 100])]\n",
    "df_train_subset = df_train[df_train.class_id.isin([2, 50, 100])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_context_images_message(df):\n",
    "    messages = []\n",
    "    grouped = df.groupby('class_id')\n",
    "    for class_id, group in grouped:\n",
    "        for _, row in group.iterrows():\n",
    "            messages.append(Image(row[\"full_image_path\"]))\n",
    "        messages.append(f\"class_id: class_{class_id}\")\n",
    "    return messages\n",
    "\n",
    "def create_input_images_message(df):\n",
    "    messages = []\n",
    "    for i, image_path in enumerate(df.full_image_path):\n",
    "        image_message = [\n",
    "            Image(image_path),\n",
    "            f\"input_image_id: {i}\",\n",
    "        ]\n",
    "        messages.extend(image_message)\n",
    "    return messages\n",
    "    \n",
    "train_images_message = create_context_images_message(df_train_subset)\n",
    "test_images_message = create_input_images_message(df_test_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; flex-wrap: wrap;\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_images_by_class(df, class_id, max_images=6):\n",
    "    images_of_class = df[df['class_id'] == class_id]\n",
    "\n",
    "\n",
    "    html_content = '<div style=\"display: flex; flex-wrap: wrap;\">'\n",
    "    for i, (_, row) in enumerate(images_of_class.iterrows()):\n",
    "        if i >= max_images:\n",
    "            break\n",
    "        html_content += f'''\n",
    "        <div style=\"margin: 10px;\">\n",
    "            <img src=\"{row['full_image_path']}\" width=\"300\">\n",
    "            <p>Image path: {row['full_image_path']}</p>\n",
    "        </div>\n",
    "        '''\n",
    "    html_content += '</div>'\n",
    "\n",
    "    display(HTML(html_content))\n",
    "\n",
    "class_id = 4\n",
    "display_images_by_class(df_train_subset, class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display: flex; flex-wrap: wrap;\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_id = 4\n",
    "display_images_by_class(df_test_subset, class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = train_images_message + test_images_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await classification_model.generate_content_async(\n",
    "    contents=contents\n",
    ")\n",
    "response_json = json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number_of_classified_images': 40,\n",
       " 'output': [{'id': '0', 'class_id': 'class_50', 'confidence': 9},\n",
       "  {'id': '1', 'class_id': 'class_50', 'confidence': 8},\n",
       "  {'id': '2', 'class_id': 'class_2', 'confidence': 7},\n",
       "  {'id': '3', 'class_id': 'class_50', 'confidence': 9},\n",
       "  {'id': '4', 'class_id': 'class_100', 'confidence': 10},\n",
       "  {'id': '5', 'class_id': 'class_2', 'confidence': 9},\n",
       "  {'id': '6', 'class_id': 'class_2', 'confidence': 8},\n",
       "  {'id': '7', 'class_id': 'class_50', 'confidence': 9},\n",
       "  {'id': '8', 'class_id': 'class_2', 'confidence': 7},\n",
       "  {'id': '9', 'class_id': 'class_50', 'confidence': 9},\n",
       "  {'id': '10', 'class_id': 'class_100', 'confidence': 9},\n",
       "  {'id': '11', 'class_id': 'class_50', 'confidence': 8},\n",
       "  {'id': '12', 'class_id': 'class_50', 'confidence': 8},\n",
       "  {'id': '13', 'class_id': 'class_50', 'confidence': 8},\n",
       "  {'id': '14', 'class_id': 'class_2', 'confidence': 7},\n",
       "  {'id': '15', 'class_id': 'class_50', 'confidence': 8},\n",
       "  {'id': '16', 'class_id': 'class_2', 'confidence': 9},\n",
       "  {'id': '17', 'class_id': 'class_50', 'confidence': 8},\n",
       "  {'id': '18', 'class_id': 'class_100', 'confidence': 9},\n",
       "  {'id': '19', 'class_id': 'class_100', 'confidence': 9},\n",
       "  {'id': '20', 'class_id': 'class_2', 'confidence': 7},\n",
       "  {'id': '21', 'class_id': 'class_50', 'confidence': 9},\n",
       "  {'id': '22', 'class_id': 'class_50', 'confidence': 9},\n",
       "  {'id': '23', 'class_id': 'class_50', 'confidence': 9},\n",
       "  {'id': '24', 'class_id': 'class_50', 'confidence': 8},\n",
       "  {'id': '25', 'class_id': 'class_100', 'confidence': 9},\n",
       "  {'id': '26', 'class_id': 'class_50', 'confidence': 9},\n",
       "  {'id': '27', 'class_id': 'class_50', 'confidence': 8},\n",
       "  {'id': '28', 'class_id': 'class_50', 'confidence': 7},\n",
       "  {'id': '29', 'class_id': 'class_50', 'confidence': 8},\n",
       "  {'id': '30', 'class_id': 'class_2', 'confidence': 7},\n",
       "  {'id': '31', 'class_id': 'class_100', 'confidence': 9},\n",
       "  {'id': '32', 'class_id': 'class_100', 'confidence': 9},\n",
       "  {'id': '33', 'class_id': 'class_100', 'confidence': 9},\n",
       "  {'id': '34', 'class_id': 'class_2', 'confidence': 8},\n",
       "  {'id': '35', 'class_id': 'class_50', 'confidence': 8},\n",
       "  {'id': '36', 'class_id': 'class_50', 'confidence': 9},\n",
       "  {'id': '37', 'class_id': 'class_2', 'confidence': 7},\n",
       "  {'id': '38', 'class_id': 'class_50', 'confidence': 9},\n",
       "  {'id': '39', 'class_id': 'class_50', 'confidence': 9}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9750\n",
      "F1-score: 0.9747\n"
     ]
    }
   ],
   "source": [
    "# Extract predictions from the response\n",
    "predictions = [int(item['class_id'].split('_')[-1]) for item in response_json['output']]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(df_test_subset.class_id, predictions)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(df_test_subset.class_id, predictions, average='weighted')\n",
    "print(f\"F1-score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
