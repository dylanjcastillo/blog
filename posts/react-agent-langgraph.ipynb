{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---\n",
    "title: \"Building ReAct agents with (and without) LangGraph\"\n",
    "date: 2025-07-04\n",
    "description-meta: \"How to build ReAct agents from scratch with (and without) LangGraph\"\n",
    "categories:\n",
    "  - llm\n",
    "  - python\n",
    "  - anthropic\n",
    "  - openai\n",
    "  - agents\n",
    "---\n",
    "\n",
    "As Large Language Models (LLMs) have become more powerful, I've started to see increasing interest from clients in building agents.\n",
    "\n",
    "The problem is that most of the use cases clients have in mind for agents are better suited for [agentic workflows](https://dylancastillo.co/posts/agentic-workflows-langgraph.html). Agents are a good fit for tasks without a predefined path and where the order of steps is not known beforehand. Agentic workflows, on the other hand, are the right choice for tasks where both of these things are known. \n",
    "\n",
    "Nonetheless, agents are still a good fit for many use cases, such as coding assistants and support agents. You should definitely spend some time learning about them.\n",
    "\n",
    "In this post, I'll show you how to build a Reasoning and Acting (ReAct) agent with (and without) LangGraph.\n",
    "\n",
    "Let's start by defining some key concepts.\n",
    "\n",
    "## What is an agent?\n",
    "\n",
    "The biggest players in the ecosystem have converged on similar definitions of what constitutes an \"agent.\" [Anthropic](https://www.anthropic.com/engineering/building-effective-agents) describes them as systems where LLMs \"dynamically direct their own processes and tool usage,\" while [OpenAI](https://openai.com/index/new-tools-for-building-agents/) calls them \"systems that independently accomplish tasks on behalf of users.\" [LangChain](https://blog.langchain.com/what-is-an-agent/) similarly defines them as systems using an LLM to \"decide the control flow of an application.\"\n",
    "\n",
    "In essence, agents are systems that can independently make decisions, use tools, take actions, and pursue a goal without direct human guidance. The most well-known agent implementation are *ReAct Agents*. \n",
    "\n",
    "## What's a ReAct agent?\n",
    "\n",
    "[ReAct (Reasoning and Acting) Agents](https://arxiv.org/abs/2210.03629) are AI systems that merge the reasoning of Large Language Models (LLMs) with the ability to perform actions. They follow an iterative \"think, act, observe\" cycle to solve problems and achieve user goals. For example, a ReAct agent would:\n",
    "\n",
    "1. Take a user query.\n",
    "2. Think about the query and decide on an action.\n",
    "3. Execute the action using available tools (environment).\n",
    "4. Analyzes the result of that action (environment).\n",
    "5. Continues the \"Reason, Act, Observe\" loop until it reaches the final answer.\n",
    "\n",
    "Here's a diagram of a ReAct agent:\n",
    "\n",
    "```{mermaid}\n",
    "graph LR\n",
    "    Human <--> LLM[LLM]\n",
    "    LLM -->|Action| Environment\n",
    "    Environment -->|Feedback| LLM\n",
    "    LLM -.-> Stop\n",
    "```\n",
    "\n",
    "\n",
    "The first generation of ReAct agents used a prompt technique of \"Thought, Action, Observation\". Current agents rely on [function-calling](https://dylancastillo.co/posts/function-calling-structured-outputs.html) to implement the \"think, act, observe\" loop.\n",
    "\n",
    "## What is LangGraph?\n",
    "\n",
    "LangGraph is a graph-based framework for building complex LLM applications, designed for stateful workflows. It makes it easier to build complex agent architectures.\n",
    "\n",
    "Graphs are composed of nodes, edges, state, and reducers. Nodes are the units of work (functions, tools) and edges define the paths between nodes. State is persistent data passed between nodes and updated through reducers (functions that define how the state is updated).\n",
    "\n",
    "I like LangGraph because it provides you with easy-to-use components, a simple API, and it lets you visualize your workflow. It also integrates well with LangSmith, a tool for monitoring and debugging LLM applications.\n",
    "\n",
    "In this tutorial, I'll show you how to build a ReAct agent with (and without) LangGraph. I'll also use *LangChain* as a thin wrapper on top of OpenAI models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To follow this tutorial you'll need to:\n",
    "\n",
    "1. Sign up and generate an API key in [OpenAI](https://platform.openai.com/docs/overview).\n",
    "2. Set the API key as an environment variable called `OPENAI_API_KEY`.\n",
    "3. Create a virtual environment in Python and install the requirements:\n",
    "\n",
    "```bash\n",
    "python -m venv venv\n",
    "source venv/bin/activate\n",
    "pip install langchain langchain-openai langchain-community langgraph jupyter\n",
    "```\n",
    "\n",
    "Once you've completed the steps above, you can run the code from this article. You can also download the notebook from [here](https://github.com/dylanjcastillo/blog/tree/main/posts/react-agent-langgraph.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "As usual, you must start by importing the necessary libraries and loading the environment variables. You'll use the same model in all the examples, so you'll define it once here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, START, MessagesState, StateGraph\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "This code: \n",
    "\n",
    "1. Imports the necessary libraries. \n",
    "2. Loads environment variables from a `.env` file using `load_dotenv()`. \n",
    "3. Defines a model (`gpt-4.1-mini`) that you'll use in all the examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla ReAct agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll build an agent that takes a question from a user and has access to a a tool. The tool is a Python REPL that it can use to answer the question. \n",
    "\n",
    "**You should not use this in production**. This tool can run arbitrary Python code on your device, and that's not something you want to expose to random people on the internet.\n",
    "\n",
    "First, let's define the `run_python_code` tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def run_python_code(code: str) -> str:\n",
    "    \"\"\"Run arbitrary Python code including imports, assignments, and statements. Do not use any external libraries. Save your results as a variable.\n",
    "\n",
    "    Args:\n",
    "        code: Python code to run\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    from io import StringIO\n",
    "\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = captured_output = StringIO()\n",
    "\n",
    "    namespace = {}\n",
    "\n",
    "    try:\n",
    "        exec(code, namespace)\n",
    "\n",
    "        output = captured_output.getvalue()\n",
    "\n",
    "        if not output.strip():\n",
    "            user_vars = {\n",
    "                k: v\n",
    "                for k, v in namespace.items()\n",
    "                if not k.startswith(\"__\") and k not in [\"StringIO\", \"sys\"]\n",
    "            }\n",
    "            if user_vars:\n",
    "                if len(user_vars) == 1:\n",
    "                    output = str(list(user_vars.values())[0])\n",
    "                else:\n",
    "                    output = str(user_vars)\n",
    "\n",
    "        return output.strip() if output.strip() else \"Code executed successfully\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "\n",
    "\n",
    "tools = [run_python_code]\n",
    "tools_mapping = {tool.name: tool for tool in tools}\n",
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a tool. In `LangChain` tools are defined as functions decorated with `@tool`. These functions must have a *docstring* because it will be used to describe the tool to the LLM. \n",
    "\n",
    "`run_python_code` is a function that takes a code string and returns the result of executing that code.\n",
    "\n",
    "Next, you provide the model with a mapping of the tool to its name by creating `tools_mapping`. This is often a point of confusion. The LLM doesn't run the tools on its own. It only decides if a tool should be used. Then, your own code must make the actual tool call. \n",
    "\n",
    "The mapping is more useful when there are multiple tools, and not a single tool, like in this case. However, I'm showing it here to illustrate how you'd usually do this in a real-world application.\n",
    "\n",
    "Finally, you _bind_ the tool to the model. The binding makes the model aware of the tool, so that it can use it. \n",
    "\n",
    "Then, let's define a function that encapsulates the logic of the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent(question: str):\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            \"You're a helpful assistant. Use the tools provided when relevant.\"\n",
    "        ),\n",
    "        HumanMessage(question),\n",
    "    ]\n",
    "    ai_message = model_with_tools.invoke(messages)\n",
    "    messages.append(ai_message)\n",
    "\n",
    "    while ai_message.tool_calls:\n",
    "        for tool_call in ai_message.tool_calls:\n",
    "            selected_tool = tools_mapping[tool_call[\"name\"]]\n",
    "            tool_msg = selected_tool.invoke(tool_call)\n",
    "            messages.append(tool_msg)\n",
    "        ai_message = model_with_tools.invoke(messages)\n",
    "        messages.append(ai_message)\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a question from a user, comes up with a python script, uses `run_python_code` to execute it and returns the result.\n",
    "\n",
    "It works as follows:\n",
    "\n",
    "- **Lines 2 to 9** set up the [prompts](https://dylancastillo.co/posts/prompt-engineering-101.html) and call the assistant. \n",
    "- **Lines 11 to 17** is where the magic happens. This is a loop that will check if there's been a tool call in the response from the model. If there is, it will call (invoke) the tool and add the result to the messages. It will then send the results back to the assistant, and repeat this process until there are no more tool calls.\n",
    "\n",
    "This is the core idea behind how agents work. You provide the assistant with a question and one or more tools. Then you let the assistant decide which tool to use, until it has all the information it needs to answer the question.\n",
    "\n",
    "You can try it out by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You're a helpful assistant. Use the tools provided when relevant.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Generate 10 random numbers between 1 and 100\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  run_python_code (call_twMJ1JkZK81ofm3842P3jNtb)\n",
      " Call ID: call_twMJ1JkZK81ofm3842P3jNtb\n",
      "  Args:\n",
      "    code: import random\n",
      "random_numbers = [random.randint(1, 100) for _ in range(10)]\n",
      "random_numbers\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: run_python_code\n",
      "\n",
      "{'random': <module 'random' from '/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/random.py'>, 'random_numbers': [74, 75, 58, 19, 90, 45, 44, 52, 90, 33]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are 10 random numbers between 1 and 100: 74, 75, 58, 19, 90, 45, 44, 52, 90, 33.\n"
     ]
    }
   ],
   "source": [
    "messages = run_agent(\"Generate 10 random numbers between 1 and 100\")\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the agent took the user's request, used the `run_python_code` tool to generate the numbers, and then returned the result.\n",
    "\n",
    "Now, let's see how you can build a ReAct agent with LangGraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangGraph ReAct agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like, in the previous example, you start by defining the tools you want to use. You'll use the same `run_python_code` tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def run_python_code(code: str) -> str:\n",
    "    \"\"\"Run arbitrary Python code including imports, assignments, and statements. Do not use any external libraries. Save your results as a variable.\n",
    "\n",
    "    Args:\n",
    "        code: Python code to run\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    from io import StringIO\n",
    "\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = captured_output = StringIO()\n",
    "\n",
    "    namespace = {}\n",
    "\n",
    "    try:\n",
    "        exec(code, namespace)\n",
    "\n",
    "        output = captured_output.getvalue()\n",
    "\n",
    "        if not output.strip():\n",
    "            user_vars = {\n",
    "                k: v\n",
    "                for k, v in namespace.items()\n",
    "                if not k.startswith(\"__\") and k not in [\"StringIO\", \"sys\"]\n",
    "            }\n",
    "            if user_vars:\n",
    "                if len(user_vars) == 1:\n",
    "                    output = str(list(user_vars.values())[0])\n",
    "                else:\n",
    "                    output = str(user_vars)\n",
    "\n",
    "        return output.strip() if output.strip() else \"Code executed successfully\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    finally:\n",
    "        sys.stdout = old_stdout\n",
    "\n",
    "\n",
    "tools = [run_python_code]\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With langgraph you also need to you define the tools in the same way: set up the functions, add `@tool`, and create the tool mapping. Then, *bind* the tools to the model.\n",
    "\n",
    "Next, you need to define the functions (nodes) that correspond to the steps the agent will take: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(state: MessagesState):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a helpful assistant that can run python code.\"),\n",
    "    ] + state[\"messages\"]\n",
    "    return {\"messages\": [model_with_tools.invoke(messages)]}\n",
    "\n",
    "\n",
    "def call_tool(state: MessagesState):\n",
    "    result = []\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    return {\"messages\": result}\n",
    "\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"environment\", END]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"Action\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how it works:\n",
    "\n",
    "1. `call_llm`: Sends the conversation history to the LLM to get the next response.\n",
    "2. `call_tool`: If the LLM's response is a request to use a tool, this function executes the tool with the specified arguments.\n",
    "3. `should_continue`: This is the control logic. It checks the LLM's last message. If it's a tool request, it routes to the `call_tool`; otherwise, it ends the conversation.\n",
    "\n",
    "`call_llm` and `call_tool` take `MessagesState` as input and return a the message key with the new message. This updates the `messages` key in the `MessagesState`. `should_continue` takes `MessagesState` act as a router, so it decides if a tool should be executed or if the conversation should end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_builder = StateGraph(MessagesState)\n",
    "\n",
    "agent_builder.add_node(\"llm\", call_llm)\n",
    "agent_builder.add_node(\"environment\", call_tool)\n",
    "\n",
    "agent_builder.add_edge(START, \"llm\")\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"Action\": \"environment\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "agent_builder.add_edge(\"environment\", \"llm\")\n",
    "\n",
    "agent = agent_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code sets up the logic of the agent. It starts with a call to the LLM. The LLM then decides whether to use a tool or to finish the task. If it uses a tool, the tool's output is sent back to the LLM for the next step. This \"think-act\" loop continues until the agent decides the task is complete.\n",
    "\n",
    "You can use `LangGraph` to visualize the agent's flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can run the agent by invoking the graph. For that, you'll need to pass a list of messages to the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that can run python code.\"),\n",
    "    HumanMessage(content=\"Generate 10 random numbers between 1 and 100\"),\n",
    "]\n",
    "\n",
    "messages = agent.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can review the process by printing the messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant that can run python code.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Generate 10 random numbers between 1 and 100\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  run_python_code (call_bsBRC5aL7kgHjeGHXaLR85TC)\n",
      " Call ID: call_bsBRC5aL7kgHjeGHXaLR85TC\n",
      "  Args:\n",
      "    code: import random\n",
      "random_numbers = [random.randint(1, 100) for _ in range(10)]\n",
      "random_numbers\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "{'random': <module 'random' from '/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/random.py'>, 'random_numbers': [77, 37, 97, 26, 22, 29, 58, 82, 17, 80]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are 10 random numbers between 1 and 100: 77, 37, 97, 26, 22, 29, 58, 82, 17, 80.\n"
     ]
    }
   ],
   "source": [
    "for m in messages[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you've learned what agents are, how they work, and how to build a simple ReAct agent with and without LangGraph. We covered:\n",
    "\n",
    "- **Agent fundamentals**: How agents differ from agentic workflows by dynamically directing their own processes\n",
    "- **ReAct pattern**: The core \"think, act, observe\" loop that enables agents to take actions based on the information they have\n",
    "- **Vanilla and LangGraph implementation**: Understanding how to implement agents with and without LangGraph \n",
    "\n",
    "Agents are great for open-ended tasks where the path isn't predetermined. If you're working on one of those, this article provides a good starting point. On the other hand, for tasks that have predefined steps, consider [agentic workflows](https://dylancastillo.co/posts/agentic-workflows-langgraph.html) instead.\n",
    "\n",
    "Hope you find this tutorial useful. If you have any questions, let me know in the comments below."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
